It is a pleasure to be here today. I appreciate the invitation to speak to you as part of this year's Banking Outlook Conference at the Federal Reserve Bank of Atlanta.1 I think this year's theme, Age of Advancement: The Intricacies of a Digital World, captures the dynamic and evolving landscape of our country's financial system well. Advances in technology are occurring at a rapid pace and present the opportunity to make our financial system safer and more efficient for more Americans.

From faster payments to artificial intelligence, technological advancements touch nearly every aspect of our financial system and affect institutions of every type. As the first Federal Reserve governor to serve in the role designated by Congress for someone with community banking experience, I am especially interested in the impact these kinds of advancements may have on community banks. I am also committed to ensuring that as policymakers and supervisors navigate the intricacies of today's digital world, we do so in a way that considers the important role of community banks in cities and towns and rural communities across the country, and our nation's financial system more broadly. To that end, I believe the Federal Reserve is well positioned to support innovation and the future of banking in a way that ensures our nation's evolving financial system works for community banks and the customers they serve. So I would like to spend my time with you today focusing on how the Federal Reserve can achieve this objective in one specific area, that of our nation's payment system.

Importance of Community Banks and the Payment System
As many of you may know, before joining the Federal Reserve, I was a community banker and more recently had the privilege to serve as the Kansas State Bank Commissioner. I have seen firsthand the vital role that our nation's community banks play in the financial industry and in the economy more broadly.

Through the services they provide, community banks help support strong cities, towns, and rural communities across the country, which are central to a vibrant economy. For example, small business lending is an essential part of community bank portfolios. Many community banks often specialize in serving small businesses, which account for the majority of new job creation in the country.2 In fact, community banks hold 48 percent of all loans to small businesses and farms in the United States.3

Community banks are also often seen by their customers as an important source of financial advice and a source of civic leadership.4 Community banks have a deep understanding of their local areas. They also have close relationships with those living in the communities they serve and the organizations that serve those communities. In many instances, community banks are also serving markets that tend to be neglected by larger banks. These connections allow community banks to focus on specific local needs to provide a variety of services, which often include tailored and innovative products. Payment services in particular are a key component of these relationships and are essential to the role of banks in their communities. Community banks help ensure that consumers and businesses can safely and efficiently access and move their money. By doing so, the payment services they provide act as the foundation for economic activities that help cities, towns, and rural communities grow and thrive, which in turn is essential to a strong and stable financial system.

A strong and stable financial system also depends on the smooth functioning of the nation's payment system. Today, many Americans take the ability to move money across the country safely and efficiently for granted, but history shows that payment system disruptions can affect the economy more broadly.5 In the past, our nation's payment system was fragmented and inefficient, creating costs for consumers, merchants, banks, and, ultimately, the U.S. economy. For example, before the Federal Reserve was established, check clearing fees and banks' efforts to avoid them often led to circuitous check routing, with recipients facing long, unpredictable delays in receiving their money. When they did eventually receive their money, fees had often consumed a considerable portion of what they were expecting. In extreme instances, this led to checks moving from city to city before eventually ending up at their destination. One often-cited example described a check that started in Rochester, New York, and traveled to Jacksonville, Florida, then to Philadelphia, Baltimore, and Cincinnati before it finally reached its final destination in Birmingham, Alabama.6 To put that in terms of miles traveled, if the check had gone directly from New York to Alabama, it would have traveled about 1,000 miles. Instead, it traveled 3,000 miles up and down the east coast, likely for days, before it finally reached its destination. The distance from Atlanta to Los Angeles is shorter than the route that check took.

These kinds of inefficiencies were so significant that one of Congress's motivations in creating the Federal Reserve was ensuring a safe and efficient nationwide payment infrastructure. Shortly after they opened for business, the Reserve Banks began providing a nationwide check collection service. This service helped speed up payments by reducing circuitous routing. It also facilitated access to more-efficient payment services for banks across the nation. Since then, the Federal Reserve has continued to support ongoing efficiency improvements in the nation's payment system, including the development of the Fedwire funds transfer system and the implementation of the automated clearinghouse, or ACH system, in partnership with the private sector.

This operational role has allowed the Federal Reserve to support the goal of a safe and efficient payment system throughout its history. It has also contributed to widespread public confidence in the nation's payment infrastructure. At times, the Federal Reserve has taken extraordinary steps to ensure the payment system can function reliably. After planes were grounded on September 11, 2001, in the aftermath of the terrorist attacks in New York and Washington, D.C., the Federal Reserve arranged alternative transportation for millions of checks that normally would have moved across the country by plane. The Federal Reserve also started giving immediate credit for all checks that it received. This provided a key source of liquidity for the payment system and temporarily caused the daily float held by the Federal Reserve to increase over 6,000 percent.7 After September 11, the Federal Reserve also took steps to improve the future efficiency of the nation's check collection system by working with Congress on the passage of the Check 21 Act in 2002.

A safe and efficient payment system also needs to be accessible, because payment services are most valuable when you can pay anyone regardless of where balances are held. The ultimate success of any effort to modernize the U.S. payment system depends on adoption across the entire banking industry. Therefore, in considering the Federal Reserve's provision of payment services, Congress took steps to try to ensure access to services across the country. As a result, Congress specifically tasked the Federal Reserve with taking into account an adequate level of services nationwide when providing and setting fees for payment services.8 The United States has a highly complex banking system with more than 10,000 depository institutions spread over wide areas with differing payment needs.9 Over 4,800 of those are community banks.10 In many areas, particularly rural areas, community banks may be the primary providers of banking services for individuals and small businesses. Community banks are, therefore, essential in ensuring access to safe and efficient payment services in towns, cities, and rural communities nationwide so that payments can move across the country regardless of geographyâ€”from here in the South, to the Midwest, and coast to coast.

Community Banks and Payment System Innovation
A diverse banking system where institutions of all sizes are able to innovate and meet evolving customer needs is essential to ensure access to safe, efficient, and modern payment services for communities across the nation. At the Federal Reserve, we support the responsible use of technology and innovation to transform the financial system and reduce frictions and delays, while preserving consumer protections, data privacy and security, and financial stability. But as technology continues to advance, the intricacies of our digital world become more complex, and I believe we can help ensure that banks are well positioned to take advantage of these technology advancements and innovations. Like the rest of the financial industry, community banks are investing in new technologies and innovations to meet the growing expectations of their customers. With their considerable understanding of local needs, community banks are able to put these kinds of innovations to use in meeting the specific needs of their communities. At the Federal Reserve, we are actively engaging with the banking industry to encourage responsible innovation in the community-banking sector.

But I also firmly believe that we cannot just say community banks need to engage in responsible innovation, we need to empower community banks to do just that, and I am committed to working with my colleagues to realize this objective. I believe it is our responsibility as a payment service provider and supervisor to ensure that our nation's evolving financial system works for community banks. Because by empowering them to provide modern and innovative services to their customers, we also ensure that Americans across the country can make payments safely and efficiently.

First, as a provider of payment services, the Federal Reserve has a long history of supporting community banks. We have long-standing relationships with, and the nationwide infrastructure to provide services to, thousands of community banks across the country. While the existing payment infrastructure provided by the Federal Reserve has generally served community banks and the nation's economy well, advances in technology have also created opportunities to modernize these payment services. Collectively, these efforts will create a modern payment infrastructure that provides community banks the ability to meet customer expectations in offering innovative services with the same effectiveness and efficiency as other providers. This in turn will provide consumers the ability to better manage their financial lives by accessing accounts when and where they choose and providing more flexibility to manage money and make time-sensitive payments.

To start, the Board has supported changes to existing Federal Reserve services. For example, at the end of last year, the Board announced changes to support adoption of an additional same-day ACH window available later in the day. When it was adopted in 2015, same-day ACH allowed for faster processing and return of recurring, low-cost payments such as payroll and bill payments. This additional window will help to make the benefits of same-day ACH more broadly accessible. More specifically, it will allow banks and their customers, particularly those located outside the eastern time zone, to use same-day ACH services during a greater portion of the business day.

Our modernization efforts do not stop with existing services, though. The FedNowSM Service, announced last August, will create a new payment infrastructure for institutions of all sizes to offer innovative faster payment services. Community banks in particular were strong supporters of developing the FedNow Service. Many of them emphasized that the Federal Reserve's long-standing policy commitment to promoting nationwide access would result in a service that is accessible to banks of all sizes. They felt that this in turn would ultimately increase the long-term likelihood of being able to offer faster payment services in their communities. Community banks continued to voice strong support in response to our most recent request for comment on the design of the FedNow Service. At the same time, they raised a number of important issues, including interoperability, time to market, and use of volume-based pricing. These issues are important to community banks, and as such, they are important to me. I intend to work with my colleagues so that the FedNow Service meets the needs of community banks and their customers. I hope that you will continue to engage with us, continue to provide your feedback, and continue to be patient as we undertake this effort to develop the FedNow Service. Because with your input, I believe the Federal Reserve can continue its long historyâ€”which started with bank notes and checks, then continued with ACHâ€”of providing infrastructure that supports the independence and success of community banks for the long term.

It is also important to understand that technology advancements affect more than just the payment infrastructure behind-the-scenes. Innovations in consumer and other end-user experiences, such as those facilitated by fintech firms, can also transform the way that consumers interact with their financial institutions, offering community banks additional opportunities to serve their customers in the future. For instance, I have previously discussed how working with fintech firms may offer community banks potential partnerships that leverage the latest technology to provide customer-first, community-focused financial services and provide customers with efficiencies, such as easy-to-use online applications or rapid loan decisionmaking. These kinds of strategic partnerships harness the indispensable knowledge and trust that community banks have built with retail customers and local small businesses. For example, we have seen community banks experience significant growth after partnering with fintech companies to offer checking accounts for online investors, personal loans, and debit cards. We have also seen such partnerships increase efficiency in service offerings, such as significantly reducing loan approval processing time. We expect that the efforts to modernize our payment infrastructure that I outlined earlier, such as FedNow, will serve as a foundation for this kind of innovation to flourish, and will support new opportunities for community banks and the communities they serve.

Of course, new technology is also subject to many of the traditional risks banks have managed in the past with more-traditional consumer services, and implementation of new technology should be driven by banks' business strategies and customer needs. Ultimately, banks remain responsible for conducting due diligence and understanding the risks faced by their organization. But technology advances quickly, and new developments inevitably raise new questions. That is why I believe that the Federal Reserve also needs to take steps as a supervisor to ensure our nation's evolving financial system works for community banks.

First and foremost, it is essential we continue to meaningfully engage with stakeholders on these issues. For example, we recently launched an innovation web page (www.federalreserve.gov/innovate) that will serve as an accessible central hub for stakeholders interested in learning about and engaging with the Federal Reserve on innovation-related matters.11 The web page can serve as a starting point for members of the industry to engage with Federal Reserve specialists, submit questions, and request in-person meetings. We also announced a series of "fintech innovation office hours" across the country. The first of these was held just yesterday here in Atlanta, and some of you may have even had the opportunity to participate. These are also an important opportunity for us to learn, and I encourage you to provide your feedback. For community banks and their potential fintech partners, I hope that these sessions will serve as a resource to meet one-on-one with Federal Reserve staff members with relevant expertise, discuss fintech developments, share specific projects, and ask questions. They also provide us an opportunity to hear directly from banks and fintech companies about challenges to innovation.

Another important area of focus for me is community banks' relationships with their vendors and third-party service providers. As a former community banker, I am acutely aware that community banks are often reliant on outside service providers and vendors to access new technologies and provide payment services. I also know that supervisory expectations in these areas can be challenging, and I have experienced it myself. There are several things I believe we can do to help provide clarity and transparency, reduce confusion, and simplify and remove some of the burden community banks face in this area.

First, in order to give community banks a better picture of what success in due diligence of third-party providers looks like, and where it begins and ends, I believe that we should release more information on its necessary elements. This change would provide clarity and assist community banks in completing their work. In particular, I believe that regulators can provide more clarity on the types of questions that should be asked of a prospective third-party provider and our view of a satisfactory answer. I also believe our guidance should explain what due diligence looks like for a potential fintech partner, because the standards applied to other third parties may not be universally applicable. Potential partnerships are not one-size-fits-all. Every bank has different objectives, and guidance should reflect some supervisory flexibility so that we do not impede prudent, strategic partnerships between community banks and potential partners. Regulators should especially support partnerships that combine the strengths of community banks and fintech companies, which have a track record of success. I also believe the Federal Reserve should allow banks to conduct shared due diligence on potential partners. If several banks use the same third-party service provider and are open to collaborating, they should be allowed to pool resources instead of duplicating one another's work. These approaches would not only have the benefit of increasing clarity and transparency for community banks, but could also be beneficial for fintech companies that hope to become third-party providers.

Second, clear and transparent guidance is most helpful when it is consistent. I have previously discussed my view that guidance on third-party relationships should be consistent across banking agencies. No one benefits when banks and their potential partners or other vendors have to navigate unnecessary differences in guidance between agencies. To that end, the Federal Reserve is in the process of working with the other banking agencies to update our third-party guidance. As part of this process, I believe that the banking agencies should all have consistent expectations for third-party relationships, and that the Federal Reserve should, as a starting point, move toward adopting the Office of the Comptroller of the Currency's guidance.

Third, I believe we can improve transparency with regard to our supervision of third parties. Through our service provider supervision program, we regularly conduct exams of many third-party service providers. While we make the outcomes available to banks that are clients of a supervised service provider, I believe we can go a step further to increase transparency by also making information that may be useful about our supervision of key service providers available to banks. This could take a number of forms, such as being more transparent about who and what we evaluate. Of course, moving forward in these areas requires careful consideration and interagency collaboration, and I have asked our staff to work with other agencies to develop and propose workable options for giving banks the benefit of the knowledge that supervisors have about their potential providers in an appropriate manner.

Finally, I believe regulators and supervisors have a role to play in ensuring that regulatory burden is tailored to bank size, risk, complexity, and capacity. Knowing the burden that third-party monitoring in particular can present to employees of the smallest banks, I have also encouraged Federal Reserve staff to consider options for further tailoring our expectations for community banks with assets under $1 billion in this area.

Collectively, I view these as important steps to improve the ability of community banks to manage their third-party relationships effectively. By doing so, I believe we will be able to better support the ability of community banks to access innovative new technology and offer modern services to customers.

Looking Ahead
The kinds of advances in technology we are discussing here today present challenges and opportunities for banks of all sizes, including community banks. Investments in new technology are likely to create implementation costs, and payment system innovations are no exception. Testing new technology, upgrading software and processing systems, and integrating new systems with existing systems will require banks to incur costs and dedicate resources to implementation. Community banks in particular may incur additional costs, for example to extend operating hours in order to facilitate payments during nonstandard business hours.

However, technological advances also present opportunities for community banks to continue serving their neighbors, and payment services are a key component of this. Since I joined the Federal Reserve, I have been on the road a lot, visiting Federal Reserve Districts and talking to bankers, consumers, and community groups. I have been struck in particular by stories I have heard about younger generations of Americans moving back to rural areas. These individuals may be returning to their hometown or moving out of urban centers, but they still have the same expectations for services like those that may be offered by larger banks with nationwide footprints. Technological developments, like the payment system modernization efforts we have discussed today, allow banks across the country to meet these customer expectations and provide payment services on a competitive basis.

I believe the Federal Reserve is uniquely positioned as a provider of payment services and as a supervisor of banks to ensure that our nation's evolving financial system works for community banks. As a provider of payment services, our efforts to modernize the nation's payment system through services like FedNow and same-day ACH will ensure community banks and their customers have access to today's financial technology nationwide. As a supervisor of banks, we can support responsible innovation by reducing regulatory burden where we can, clarifying expectations, and improving the ability of community banks to manage their relationships effectively. Collectively, I believe these efforts will help support a community banking sector that is well positioned to thrive and offer modern, innovative services to their customers. By providing such services, community banks can help ensure all Americans can make payments safely and efficiently regardless of their location and that families across the country have access to financial services that are so important to their success and the success of our communities in today's age of advancement.

Thank you for the opportunity to participate again this year in the Annual Economic Policy Conference of the National Association for Business Economics. I am really looking forward to this conversation. But first, I would like to share with you some thoughts about the outlook for the U.S. economy and monetary policy.1

In its 11th year of a record expansion, the U.S. economy is in a good place. The labor market remains strong, economic activity is increasing at a moderate pace, and the Federal Open Market Committee's (FOMC) baseline outlook is for a continuation of this performance in 2020.2 At present, personal consumption expenditures, or PCE, price inflation is running somewhat below the Committee's 2 percent objective, but we project that, under appropriate monetary policy, inflation will rise gradually to our symmetric 2 percent objective. Although the unemployment rate is around a 50-year low, wages are rising broadly in line with productivity growth and underlying inflation. We are not seeing any evidence to date that a strong labor market is putting excessive cost-push pressure on price inflation.

Although the fundamentals supporting household consumption remain solid, over 2019, sluggish growth abroad and global developments weighed on investment, exports, and manufacturing in the United States. Coming into this year, indications suggested that headwinds to global growth had begun to abate, and uncertainties around trade policy had diminished. However, risks to the outlook remain. In particular, we are closely monitoring the emergence of the coronavirus, which is likely to have a noticeable impact on Chinese growth, at least in the first quarter of this year. The disruption there could spill over to the rest of the global economy. But it is still too soon to even speculate about either the size or the persistence of these effects, or whether they will lead to a material change in the outlook. In addition, U.S. inflation remains muted. And inflation expectationsâ€”those measured by surveys, market prices, and econometric modelsâ€”reside at the low end of a range I consider consistent with our price-stability mandate.

Over the course of 2019, the FOMC undertook a shift in the stance of monetary policy to offset some significant global growth headwinds and global disinflationary pressures. I believe this shift was well timed and has been providing support to the economy and helping to keep the U.S. outlook on track. Monetary policy is in a good place and should continue to support sustained growth, a strong labor market, and inflation returning to our symmetric 2 percent objective. As long as incoming information about the economy remains broadly consistent with this outlook, the current stance of monetary policy likely will remain appropriate.

That said, monetary policy is not on a preset course. The Committee will proceed on a meeting-by-meeting basis and will be monitoring the effects of our recent policy actions along with other information bearing on the outlook as we assess the appropriate path of the target range for the federal funds rate. Of course, if developments emerge that, in the future, trigger a material reassessment of our outlook, we will respond accordingly.

In January 2019, my FOMC colleagues and I affirmed that we aim to operate with an ample level of bank reserves in the U.S. financial system.3 And in October, we announced and began to implement a program to address pressures in repurchase agreement (repo) markets that became evident in September.4 To that end, we have been purchasing Treasury bills and conducting both overnight and term repurchase operations. These efforts have been successful in achieving stable money market conditions, including over the year-end. As our bill purchases continue to build reserves toward levels that we associate with ample conditions, we intend to gradually transition away from the active use of repo operations. And as reserves reach durably ample levels, we intend to slow the pace of purchases such that our balance sheet grows in line with trend demand for our liabilities. Let me emphasize that we stand ready to adjust the details of this program as appropriate and in line with our goal, which is to keep the federal funds rate in the target range desired by the FOMC, and that these operations are technical measures not intended to change the stance of monetary policy.

Finally, allow me to offer a few words about the FOMC's review of the monetary policy strategy, tools, and communication practices that we commenced in 2019. This reviewâ€”with public engagement unprecedented in scope for usâ€”is the first of its kind for the Federal Reserve. Through 14 Fed Listens events, including a research conference in Chicago, we have been hearing a range of perspectives not only from academic experts, but also from representatives of consumer, labor, community, business, and other groups. We are drawing on these insights as we assess how best to achieve and maintain maximum employment and price stability. In July, we began discussing topics associated with the review at regularly scheduled FOMC meetings. We will continue reporting on our discussions in the minutes of FOMC meetings and will share our conclusions with the public when we complete the review later this year.5

Thank you very much for your time and attention. I look forward to the conversation and the question-and-answer session to follow.


Thank you to the conference organizers for inviting me here to discuss what former Chair Bernanke has famously referred to as a "hall of mirrors" problem: a situation in which a central bank's reaction function and financial market prices interact in economically suboptimal and potentially destabilizing ways.1 In my remarks today, I will lay out the way I think about the interplay between financial markets and monetary policy, with a focus on how I myself seek to integrate noisy but often correlated signals about the economy that I glean from models, surveys, and financial markets.2

Three Observations
I begin with three unobjectionable observations. First, because of Friedman's long and variable lags, monetary policy should beâ€”and, at the Fed, isâ€”forward looking. Policy decisions made today will have no effect on today's inflation or unemployment rates, so good policy needs to assess where the economic fundamentals are going tomorrow to calibrate appropriate policy today. Of course, financial markets are also forward looking. An asset's value today depends upon its expected future cash flows discounted by a rate that reflects the expected path of the policy rate plus an appropriate risk premium. Thus, central banks and financial markets are looking at the same data on macro fundamentals to make inferences about the future path of the economy, and, of course, any decisions on the policy path made by the central bank will influence asset prices through the discount factor. So optimal monetary policy will (almost) always be correlated with asset prices. Correlation is not evidence of causation, and the hall of mirrors problem at its essence is about inferring causation from correlation.

Second, because key variables that are crucial inputs for conducting monetary policyâ€”such as r*, u*, and expected inflation, to name just threeâ€”are both unobserved and time varying, responsible monetary policy requires informed views about how these variables evolve over time as well as a humility and an appreciation for the uncertainties surrounding baseline views, however well informed they might be.

Third, when trying to make an inference about unobserved variables like r* or expected inflation, it is generally a good idea to seek data from multiple signals correlated with the variable of interest, so long as the signals themselves are not perfectly correlated with one another. Think of this third unobjectionable observation as a sort of "model averaging" or "triangulation" principle of robust inference in a noisy and complex environment.3

Data Dependence
As I have written before, monetary policy needs to beâ€”and, at the Fed, isâ€” "data dependent" in two distinct ways.4 Policy should be data dependent in the sense that incoming data indicate the position of the economy relative to the ultimate objectives of price stability and maximum employment. This information on where the economy is relative to the goals of monetary policy is an important input into standard interest rate feedback rules, such as those introduced by John Taylor in 1993 and ones that continue today to inform monetary policy decisions at the Fed and at other central banks.5

Monetary policy, however, also needs to be data dependent in the second senseâ€”that incoming data contain signalsâ€”that can enable the central bank to update its estimates of r* and u* in order to obtain its best estimate of the destination to which the economy is heading. As I mentioned a moment ago, a challenge for policymakers is that key variables that are essential inputs to monetary policyâ€”such as u*, r*, and expected inflationâ€”cannot be observed directly and must be inferred from observed data. And as is indicated in the Summary of Economic Projections, Federal Open Market Committee (FOMC) participants have, over the past seven years, repeatedly revised down their estimates of both u* and r* as unemployment fell and as real interest rates remained well below previous estimates of neutral without the rise in inflation those earlier estimates would have predicted. I would argue that these revisions to u* and r* indicate that the FOMC has been data dependent in this second sense and that these updated assessments of u* and r* have had an important influence on the path for the policy rate actually implemented in recent years. Indeed, had the Fed not been data dependent in this second sense and remained closed to the possibility that the economy had changed and historical estimates of r* and u* needed to be revised, that stubbornness would have represented a material policy mistake.

In addition to u* and r*, an important input into any monetary policy assessment is the state of inflation expectations. One of the robust messages from the DSGE (dynamic stochastic general equilibrium) literature on optimal monetary policy is that, away from the effective lower bound, optimal monetary policy will not eliminate all inflation volatilityâ€”there are always shocksâ€”but will, under rational expectations (RE), deliver average, and under RE, expected, inflation equal to the target. Since the late 1990s, inflation expectations appear to have been stable and well anchored in the neighborhood of our 2 percent goal. However, like r* and u*, inflation expectations are not directly observable and so must be inferred from data. But which data?

Financial Data and Monetary Policy
Let me now discuss in more detail how I use a form of model averaging to combine financial market data with data from surveys and econometric models to inform my thinking about the evolution of two key inputs to monetary policy: r* and long-run expected inflation. To be sure, financial market signals are noisy, and day-to-day movements in asset prices are unlikely to tell us much about the cyclical or structural position of the economy, let alone r* and expected inflation. However, persistent shifts in financial market conditions can be informative. Signals derived from financial market data, when combined with signals revealed from surveys of households and firms along with the filtered estimates from econometric models, can together provide valuable and reasonably robust foundations for real-time inference about the direction of travel in r* and expected inflation.

For example, a "straight read" of interest rate futures prices provides one source of high-frequency information about the destination for the federal funds rate expected by market participants. The destination for the federal funds rate implied by a straight read of futures prices is in turn the sum of the market-implied r* plus market-implied expected inflation. But these signals from interest rate futures are only a pure measure of the expected policy rate path under the assumption of a zero risk premium. For this reason, it is useful to compare policy rate paths derived from market prices with the path obtained from surveys of market participants, which, while subject to measurement error, should not be contaminated with a term premium. Market- and survey-based estimates of the policy rate path are often highly correlated. But when there is a divergence between the path or destination for the policy rate implied by the surveys and a straight read of interest rate derivatives prices, I place at least as much weight on the survey evidenceâ€”for example, derived from the surveys of primary dealers and market participants conducted by the Federal Reserve Bank of New Yorkâ€”as I do on the estimates obtained from market prices. Finally, as another reality check, I, of course, always consult the latest estimate of r* produced by the Laubach and Williams (2003) unobservable components state-space model, which, I should point out, includes no information on asset prices other than the short-term nominal interest rate itself.6

Quotes from the Treasury Inflation-Protected Securities (TIPS) market can provide valuable information about both r* and expected inflation. TIPS market data, together with nominal Treasury yields, can be used to construct measures of "breakeven inflation" or inflation compensation that provide a noisy signal of market expectations of future inflation. But, again, a straight read of breakeven inflation based on TIPS curve forward real rates needs to be augmented with a model to filter out the liquidity and risk premium components that place a wedge between inflation compensation and expected inflation.

It is again useful to compare estimates of expected inflation derived from breakeven inflation data with estimates of expected inflation obtained from surveysâ€”for example, the expected inflation over the next 5 to 10 years from the University of Michigan Surveys of Consumers. Market- and survey-based estimates of expected inflation are correlated, but, again, when there is a divergence between the two, I place at least as much weight on the survey evidence as on the market-derived estimates. Again, here I also consult time-series models of underlying inflation, such as Stock and Watson (2007) and Cecchetti and others (2017), presented at the U.S. Monetary Policy Forum in 2017.7 At the Fed, the staff have estimated a state-space model decomposition of the common factor that drives a number of different measures of inflation expectations. State-space econometrics is one formal way to do model averaging. As I look at all of this evidence from market signals, surveys, and econometric models, I judge that inflation expectations reside at the low end of the range I consider consistent with our price-stability goal of 2 percent personal consumption expenditure inflation in the long run.

In both of the examples I have just discussed, the medium-frequency evolution of market-based, survey-based, and model-based estimates of r* and expected inflation have, over time, tended to move broadly together. When high-frequency market signals diverge from the survey- and model-based estimates, the potential benefit from increasing the weight on a signal derived from a forward-looking asset price versus backward estimates from models and slowly evolving surveys must be balanced against the cost of treating the noise in the asset price as a signal. There is no unique way to do this, and judgment is required.

In conclusion, while my colleagues and I are attuned to the potential for a hall of mirrors problem, in my experience this affliction is one the Federal Reserve guards against and does not suffer from. My colleagues and I do look at developments in asset markets, but never in isolation and always in the context of balancing asset market signals with complementary signals from surveys and econometric models. It is fair to say that when signals from all three sources line up in the same directionâ€”as, for example, has been the case with market-, survey-, and model-based estimates of r*â€”the effect of those combined signals, at least on my thinking about the policy path, is more material than when the signals provide conflicting interpretations.

Thank you for your attention. I look forward to hearing from the other panelists and to our discussion.

Comments on Monetary Policy in the Next Recession?, a report by Stephen Cecchetti, Michael Feroli, Anil Kashyap, Catherine Mann, and Kim Schoenholtz

I want to thank Anil Kashyap and the Initiative on Global Markets for inviting me, along with my colleague Raphael Bostic, to comment on this year's U.S. Monetary Policy Forum report by a distinguished set of authors.1 This year's report addresses the challenges that monetary policy is likely to encounter in the next downturn. This topic is under active review by the Federal Reserve and our peers in many other economies.2

Looking Back
The report explores the important question of whether the new monetary policy tools are likely to be sufficiently powerful in the next downturn. The report assesses how unconventional toolsâ€”including forward guidance, balance sheet policies, negative nominal interest rates, yield curve control, and exchange rate policiesâ€”have performed over the past few decades. It employs a novel approach by examining the effect on an index of financial conditions the authors construct. This approach adds to what we have learned from earlier papers that have examined the performance of unconventional policy tools with respect to individual components of financial conditionsâ€”most notably, long-term sovereign yields, but also mortgage rates, equities, exchange rates, and corporate debt spreads.3

Empirically assessing the question in the report is not only important, but also challenging, as the report readily acknowledges. There are a host of difficult endogeneity and omitted-variable issues, which the authors endeavor to address. The authors conclude that unconventional monetary policies worked during the crisis but did not fully offset a significant tightening in financial conditions. This finding leads the authors to conclude that these policies should be deployed quickly and aggressively in the future through a plan that is communicated in advance. This point is very important, so it will be the focus of my discussion.

Looking back at the international experience, the evidence suggests that forward guidance and balance sheet policies were broadly effective in providing accommodation following the financial crisis. But they were less effective when there were long delays in implementation or apparent inconsistencies among policy tools. It is important to distill key lessons from the past use of these tools in order to make them more effective in the future.4

First, in some cases around the world, unconventional tools were implemented only after long delays and debate, which sapped confidence, tightened financial conditions, and weakened recovery. The delays often reflected concerns about the putative costs and risks of these policies, such as stoking high inflation and impairing market functioning. These costs and risks did not materialize or proved manageable, and I expect these tools to be deployed more forcefully and readily in the future.5

Second, forward guidance proved to be vital during the crisis, but it took some time to recognize the importance of conditioning forward guidance on specific outcomes or dates and to align the full set of policy tools. In several cases, the targeted outcomes set too low a bar, which in turn diminished market expectations regarding monetary accommodation. In some cases, expectations regarding the timing of liftoff and asset purchase tapering worked at cross-purposes.

In addition, in some cases, it proved difficult to calibrate asset purchase programs smoothly over the course of the recovery. To the extent that the public is uncertain about the conditions that might trigger asset purchases, the scale of purchases, and how long the purchases might be sustained, it could undercut the efficacy of the policy. Furthermore, the cessation of asset purchases and subsequent balance sheet normalization can present challenges in communications and implementation.

Finally, in the fog of war, it was difficult for policymakers to distinguish clearly between temporary headwinds associated with the crisis and emerging structural features of the new normal. In part as a result, it took some time to integrate forward guidance and other unconventional policies seamlessly, and it took even longer to recognize that policy settings were unlikely to return to pre-crisis norms.

Looking Ahead
The current generation of central bankers faces a different core challenge than the last generation, with substantially smaller scope for cutting interest rates to buffer the economy and inflation that is low and relatively unresponsive to resource utilization. With trend inflation running below the symmetric 2 percent objective, there is a risk that inflation expectations have slipped. With price inflation showing little sensitivity to resource utilization, policy may have to remain accommodative for a long time to achieve 2 percent inflation following a period of undershooting. With the equilibrium interest rate very low, the Federal Open Market Committee can cut the federal funds rate by only about half as much as it has done historically to buffer the economy from recession. Consequently, the policy rate is likely to be constrained by the lower bound more frequently, likely at times when inflation is below target and unemployment is elevated. The likelihood that the policy rate will be stuck at the lower bound more frequently risks eroding expected inflation and actual inflation, which could further compress the room to cut nominal interest rates in a downward spiral. Japan's experience illustrates the challenges associated with such a downward spiral.

Today's new normal calls not only for a broader set of tools, but also a different strategy.6 We should clarify in advance that we will deploy a broader set of tools proactively to provide accommodation when shocks are likely to push the policy rate to its lower bound. Equally important, we should adopt a strategy that successfully achieves maximum employment and average inflation outcomes of 2 percent over time.

The lessons from the crisis would argue for an approach that commits to maintain policy at the lower bound until full employment and target inflation are achieved. This forward guidance could be reinforced by interest rate caps on short-term Treasury securities over the same horizon. To have the greatest effect, it will be important to communicate and explain the framework in advance so that the public anticipates the approach and takes it into account in their spending and investment decisions.

Forward guidance that commits to refrain from lifting the policy rate from its lower bound until full employment and 2 percent inflation are achieved is vital to ensure achievement of our dual-mandate goals with compressed conventional policy space.7 To strengthen the credibility of the forward guidance, interest rate caps could be implemented in tandem as a commitment mechanism. Based on its assessment of how long it is likely to take to achieve full employment and target inflation, the Committee would commit to capping rates out the yield curve for a period consistent with its expectation for the duration of the outcome-based forward guidance. Of course, if the outlook shifted materially, the Committee could reassess how long it will take to reach its goals and adjust policy accordingly.

One important benefit is that this approach would smoothly move to capping interest rates on the short-to-medium segment of the yield curve once the policy rate moves to the lower bound and avoid the risk of delays or uncertainty that could be associated with asset purchases regarding the scale and timeframe. The interest rate caps would transmit additional accommodation through the longer rates that are relevant for households and businesses in a manner that is more akin to conventional policy and more continuous than quantitative asset purchases.

Another important benefit is that the forward guidance and the yield curve caps would reinforce each other. Setting the horizon on the interest rate caps to reinforce forward guidance on the policy rate would augment the credibility of the yield curve caps and thereby diminish concerns about an open-ended balance sheet commitment. Once target inflation and full employment are achieved, and the caps expire, any short-to-medium-term Treasury securities that were acquired under the program would roll off organically, unwinding the policy smoothly and predictably. This approach should avoid some of the tantrum dynamics that have led to premature steepening of the yield curve in several jurisdictions.8

Today's low-inflation, low interest rate environment requires not only new recession-fighting tools but also a new strategy to address the persistent undershooting of the inflation targetâ€”and the risk to inflation expectationsâ€”well before a downturn. Various strategies have been proposed that seek to make up for past inflation deviations from target.9 To be successful, formal makeup strategies, such as an average-inflation-targeting rule, require that market participants, households, and businesses understand the policy in advance and find it credible. While formal average-inflation-targeting rules have some attractive properties in theory, they could be difficult to communicate and implement in practice due to time-inconsistency problems as well as uncertainty about underlying economic parameters.10

I prefer flexible inflation averaging that would aim to achieve inflation outcomes that average 2 percent over time. Flexible inflation averaging would imply supporting inflation a bit above 2 percent for some time to compensate for the inflation shortfall over previous years and anchor inflation expectations at 2 percent. Flexible inflation averaging would bring some of the benefits of a formal average-inflation-targeting rule, but it could be more robust and simpler to communicate and implement. Following several years when inflation has remained in the range of 1-1/2 to 2 percent, the Committee could target inflation outcomes in a range of 2 to 2-1/2 percent for a period to achieve inflation outcomes of 2 percent, on average, overall.

By committing to achieve inflation outcomes that average 2 percent over time, the Committee would make clear in advance that it would accommodate rather than offset modest upward pressures to inflation in what could be described as a process of opportunistic reflation.11 This approach will help move inflation expectations back to our 2 percent objective, which is critical to preserve conventional policy space.

It is important to emphasize that for monetary policy to be effective, it will be key for policymakers to communicate their strategy clearly in advance to the public, to act early and decisively, and to commit to providing the requisite accommodation until full employment and target inflation are sustainably achieved. This was one of the important conclusions of this year's U.S. Monetary Policy Forum report.

Fiscal Policy
Even with a revamped monetary policy strategy and expanded tools, there are risks. As the authors note, persistent very low levels of long-run rates could hamper the ability of monetary policy to support the economy in a downturn through the traditional mechanism of pushing down long-term rates.12 Moreover, the equilibrium interest rate or, possibly, inflation expectations could be lower than most current estimates, with the implication that unconventional policies would need to compensate for a larger reduction in the conventional policy buffer.13

Accordingly, in addition to a forceful response from monetary policy, robust countercyclical fiscal policy is vital. The reduced conventional monetary policy buffer makes the importance of fiscal support during a downturn even greater than it has been in the past, and the case for fiscal support is especially compelling in the context of very low long-term interest rates. Not only is fiscal policy more vital when monetary policy is constrained by the lower bound, but research suggests it is also more powerful.14

Whereas monetary policy is powerful but blunt, fiscal policy can be more targeted in its effects. This is especially important today, when a large share of American households have low liquid savings and are particularly vulnerable to periods of unemployment or underemployment.

The appropriate design of a more automatic, faster-acting countercyclical fiscal approach requires study and development. Just as monetary policymakers are actively reviewing their tools and strategies, now is the time to undertake a review of fiscal tools and strategies to ensure they are ready and effective.

Financial Stability
Financial stability is central to the achievement of our dual-mandate goals. The new normal of low interest rates and inflation also has implications for the interplay between financial stability and monetary policy. In the decades when the Phillips curve was steeper, inflation tended to rise as the economy heated up, which would prompt the Committee to raise interest rates to restrictive levels. These interest rate increases would have the effect of tightening financial conditions more broadly, thereby naturally damping financial imbalances as the expansion extends.

With trend inflation persistently below target and a flat Phillips curve, not only is the policy rate expected be low for long due to the decline in the neutral rate, but the policy rate may also remain below the neutral rate for longer in order to move inflation back to target sustainably. The expectation of a long period of accommodative monetary policy and low rates, during a period with sustained high rates of resource utilization, is conducive to risk-taking, providing incentives to reach for yield and take on additional debt.

To the extent that the combination of a low neutral rate, a flat Phillips curve, and low underlying inflation may lead financial imbalances to become more tightly linked to the business cycle, it is important to use tools other than monetary policy to temper the financial cycle. In today's new normal, a combination of strengthened structural safeguards along with countercyclical macroprudential tools is important to enable monetary policy to stay focused on achieving maximum employment and target inflation.15 The countercyclical capital buffer, which was not available before the crisis, is particularly well designed to address financial imbalances over the cycle.

Conclusion
With the policy rate more likely to be constrained by the lower bound, the core challenge facing the current generation of central bankers is different than the last generation. The authors of the report emphasize the importance of deploying an expanded toolkit proactively, avoiding costly delays, and communicating clearly to the public. To be fully effective, proactive use of an expanded toolkit needs to be coupled with a new strategy that achieves average inflation outcomes of 2 percent along with maximum employment over time.

Comments on Monetary Policy in the Next Recession?, a report by Stephen Cecchetti, Michael Feroli, Anil Kashyap, Catherine Mann, and Kim Schoenholtz

I want to thank Anil Kashyap and the Initiative on Global Markets for inviting me, along with my colleague Raphael Bostic, to comment on this year's U.S. Monetary Policy Forum report by a distinguished set of authors.1 This year's report addresses the challenges that monetary policy is likely to encounter in the next downturn. This topic is under active review by the Federal Reserve and our peers in many other economies.2

Looking Back
The report explores the important question of whether the new monetary policy tools are likely to be sufficiently powerful in the next downturn. The report assesses how unconventional toolsâ€”including forward guidance, balance sheet policies, negative nominal interest rates, yield curve control, and exchange rate policiesâ€”have performed over the past few decades. It employs a novel approach by examining the effect on an index of financial conditions the authors construct. This approach adds to what we have learned from earlier papers that have examined the performance of unconventional policy tools with respect to individual components of financial conditionsâ€”most notably, long-term sovereign yields, but also mortgage rates, equities, exchange rates, and corporate debt spreads.3

Empirically assessing the question in the report is not only important, but also challenging, as the report readily acknowledges. There are a host of difficult endogeneity and omitted-variable issues, which the authors endeavor to address. The authors conclude that unconventional monetary policies worked during the crisis but did not fully offset a significant tightening in financial conditions. This finding leads the authors to conclude that these policies should be deployed quickly and aggressively in the future through a plan that is communicated in advance. This point is very important, so it will be the focus of my discussion.

Looking back at the international experience, the evidence suggests that forward guidance and balance sheet policies were broadly effective in providing accommodation following the financial crisis. But they were less effective when there were long delays in implementation or apparent inconsistencies among policy tools. It is important to distill key lessons from the past use of these tools in order to make them more effective in the future.4

First, in some cases around the world, unconventional tools were implemented only after long delays and debate, which sapped confidence, tightened financial conditions, and weakened recovery. The delays often reflected concerns about the putative costs and risks of these policies, such as stoking high inflation and impairing market functioning. These costs and risks did not materialize or proved manageable, and I expect these tools to be deployed more forcefully and readily in the future.5

Second, forward guidance proved to be vital during the crisis, but it took some time to recognize the importance of conditioning forward guidance on specific outcomes or dates and to align the full set of policy tools. In several cases, the targeted outcomes set too low a bar, which in turn diminished market expectations regarding monetary accommodation. In some cases, expectations regarding the timing of liftoff and asset purchase tapering worked at cross-purposes.

In addition, in some cases, it proved difficult to calibrate asset purchase programs smoothly over the course of the recovery. To the extent that the public is uncertain about the conditions that might trigger asset purchases, the scale of purchases, and how long the purchases might be sustained, it could undercut the efficacy of the policy. Furthermore, the cessation of asset purchases and subsequent balance sheet normalization can present challenges in communications and implementation.

Finally, in the fog of war, it was difficult for policymakers to distinguish clearly between temporary headwinds associated with the crisis and emerging structural features of the new normal. In part as a result, it took some time to integrate forward guidance and other unconventional policies seamlessly, and it took even longer to recognize that policy settings were unlikely to return to pre-crisis norms.

Looking Ahead
The current generation of central bankers faces a different core challenge than the last generation, with substantially smaller scope for cutting interest rates to buffer the economy and inflation that is low and relatively unresponsive to resource utilization. With trend inflation running below the symmetric 2 percent objective, there is a risk that inflation expectations have slipped. With price inflation showing little sensitivity to resource utilization, policy may have to remain accommodative for a long time to achieve 2 percent inflation following a period of undershooting. With the equilibrium interest rate very low, the Federal Open Market Committee can cut the federal funds rate by only about half as much as it has done historically to buffer the economy from recession. Consequently, the policy rate is likely to be constrained by the lower bound more frequently, likely at times when inflation is below target and unemployment is elevated. The likelihood that the policy rate will be stuck at the lower bound more frequently risks eroding expected inflation and actual inflation, which could further compress the room to cut nominal interest rates in a downward spiral. Japan's experience illustrates the challenges associated with such a downward spiral.

Today's new normal calls not only for a broader set of tools, but also a different strategy.6 We should clarify in advance that we will deploy a broader set of tools proactively to provide accommodation when shocks are likely to push the policy rate to its lower bound. Equally important, we should adopt a strategy that successfully achieves maximum employment and average inflation outcomes of 2 percent over time.

The lessons from the crisis would argue for an approach that commits to maintain policy at the lower bound until full employment and target inflation are achieved. This forward guidance could be reinforced by interest rate caps on short-term Treasury securities over the same horizon. To have the greatest effect, it will be important to communicate and explain the framework in advance so that the public anticipates the approach and takes it into account in their spending and investment decisions.

Forward guidance that commits to refrain from lifting the policy rate from its lower bound until full employment and 2 percent inflation are achieved is vital to ensure achievement of our dual-mandate goals with compressed conventional policy space.7 To strengthen the credibility of the forward guidance, interest rate caps could be implemented in tandem as a commitment mechanism. Based on its assessment of how long it is likely to take to achieve full employment and target inflation, the Committee would commit to capping rates out the yield curve for a period consistent with its expectation for the duration of the outcome-based forward guidance. Of course, if the outlook shifted materially, the Committee could reassess how long it will take to reach its goals and adjust policy accordingly.

One important benefit is that this approach would smoothly move to capping interest rates on the short-to-medium segment of the yield curve once the policy rate moves to the lower bound and avoid the risk of delays or uncertainty that could be associated with asset purchases regarding the scale and timeframe. The interest rate caps would transmit additional accommodation through the longer rates that are relevant for households and businesses in a manner that is more akin to conventional policy and more continuous than quantitative asset purchases.

Another important benefit is that the forward guidance and the yield curve caps would reinforce each other. Setting the horizon on the interest rate caps to reinforce forward guidance on the policy rate would augment the credibility of the yield curve caps and thereby diminish concerns about an open-ended balance sheet commitment. Once target inflation and full employment are achieved, and the caps expire, any short-to-medium-term Treasury securities that were acquired under the program would roll off organically, unwinding the policy smoothly and predictably. This approach should avoid some of the tantrum dynamics that have led to premature steepening of the yield curve in several jurisdictions.8

Today's low-inflation, low interest rate environment requires not only new recession-fighting tools but also a new strategy to address the persistent undershooting of the inflation targetâ€”and the risk to inflation expectationsâ€”well before a downturn. Various strategies have been proposed that seek to make up for past inflation deviations from target.9 To be successful, formal makeup strategies, such as an average-inflation-targeting rule, require that market participants, households, and businesses understand the policy in advance and find it credible. While formal average-inflation-targeting rules have some attractive properties in theory, they could be difficult to communicate and implement in practice due to time-inconsistency problems as well as uncertainty about underlying economic parameters.10

I prefer flexible inflation averaging that would aim to achieve inflation outcomes that average 2 percent over time. Flexible inflation averaging would imply supporting inflation a bit above 2 percent for some time to compensate for the inflation shortfall over previous years and anchor inflation expectations at 2 percent. Flexible inflation averaging would bring some of the benefits of a formal average-inflation-targeting rule, but it could be more robust and simpler to communicate and implement. Following several years when inflation has remained in the range of 1-1/2 to 2 percent, the Committee could target inflation outcomes in a range of 2 to 2-1/2 percent for a period to achieve inflation outcomes of 2 percent, on average, overall.

By committing to achieve inflation outcomes that average 2 percent over time, the Committee would make clear in advance that it would accommodate rather than offset modest upward pressures to inflation in what could be described as a process of opportunistic reflation.11 This approach will help move inflation expectations back to our 2 percent objective, which is critical to preserve conventional policy space.

It is important to emphasize that for monetary policy to be effective, it will be key for policymakers to communicate their strategy clearly in advance to the public, to act early and decisively, and to commit to providing the requisite accommodation until full employment and target inflation are sustainably achieved. This was one of the important conclusions of this year's U.S. Monetary Policy Forum report.

Fiscal Policy
Even with a revamped monetary policy strategy and expanded tools, there are risks. As the authors note, persistent very low levels of long-run rates could hamper the ability of monetary policy to support the economy in a downturn through the traditional mechanism of pushing down long-term rates.12 Moreover, the equilibrium interest rate or, possibly, inflation expectations could be lower than most current estimates, with the implication that unconventional policies would need to compensate for a larger reduction in the conventional policy buffer.13

Accordingly, in addition to a forceful response from monetary policy, robust countercyclical fiscal policy is vital. The reduced conventional monetary policy buffer makes the importance of fiscal support during a downturn even greater than it has been in the past, and the case for fiscal support is especially compelling in the context of very low long-term interest rates. Not only is fiscal policy more vital when monetary policy is constrained by the lower bound, but research suggests it is also more powerful.14

Whereas monetary policy is powerful but blunt, fiscal policy can be more targeted in its effects. This is especially important today, when a large share of American households have low liquid savings and are particularly vulnerable to periods of unemployment or underemployment.

The appropriate design of a more automatic, faster-acting countercyclical fiscal approach requires study and development. Just as monetary policymakers are actively reviewing their tools and strategies, now is the time to undertake a review of fiscal tools and strategies to ensure they are ready and effective.

Financial Stability
Financial stability is central to the achievement of our dual-mandate goals. The new normal of low interest rates and inflation also has implications for the interplay between financial stability and monetary policy. In the decades when the Phillips curve was steeper, inflation tended to rise as the economy heated up, which would prompt the Committee to raise interest rates to restrictive levels. These interest rate increases would have the effect of tightening financial conditions more broadly, thereby naturally damping financial imbalances as the expansion extends.

With trend inflation persistently below target and a flat Phillips curve, not only is the policy rate expected be low for long due to the decline in the neutral rate, but the policy rate may also remain below the neutral rate for longer in order to move inflation back to target sustainably. The expectation of a long period of accommodative monetary policy and low rates, during a period with sustained high rates of resource utilization, is conducive to risk-taking, providing incentives to reach for yield and take on additional debt.

To the extent that the combination of a low neutral rate, a flat Phillips curve, and low underlying inflation may lead financial imbalances to become more tightly linked to the business cycle, it is important to use tools other than monetary policy to temper the financial cycle. In today's new normal, a combination of strengthened structural safeguards along with countercyclical macroprudential tools is important to enable monetary policy to stay focused on achieving maximum employment and target inflation.15 The countercyclical capital buffer, which was not available before the crisis, is particularly well designed to address financial imbalances over the cycle.

Conclusion
With the policy rate more likely to be constrained by the lower bound, the core challenge facing the current generation of central bankers is different than the last generation. The authors of the report emphasize the importance of deploying an expanded toolkit proactively, avoiding costly delays, and communicating clearly to the public. To be fully effective, proactive use of an expanded toolkit needs to be coupled with a new strategy that achieves average inflation outcomes of 2 percent along with maximum employment over time.

Thank you to the American Bankers Association for inviting me to address this year's Conference for Community Bankers. I am delighted to be here with you again. Let me begin by stating that the views I express today are my own, and not necessarily those of the Federal Reserve.

As community bankers, you have worked hard to develop a deep understanding of your local economies, while also keeping perspective on the broader economic picture. There is little I could tell you about your local communities that you do not already know, but I thought I might say a few words on the national economic outlook before turning to my main topic for today.

My colleagues and I on the Federal Open Market Committee had our most recent meeting about two weeks ago, when we decided to keep our target range for the federal funds rate unchanged at 1-1/2 to 1-3/4 percent. This policy setting should help support the economic expansion, which is now in its 11th year. My outlook for the U.S. economy is for continued growth at a moderate pace, with the unemployment rateâ€”which is the lowest it has been in 50 yearsâ€”remaining low. I also see inflation gradually rising to the Committee's 2 percent objective. So on the whole, the national economic backdrop looks very favorable, which should be broadly supportive of your local economies. And of course, by ensuring that consumers and businesses in your communities have access to financial services, you are key contributors to the health of our national economy.

Let me now turn to my main topic for today, the interaction between innovation and regulation for community banks. As the Federal Reserve Board's first designated governor with experience in community banking, I am committed to maintaining a strong and thriving community bank sector. Small banks are the lifeblood of their communitiesâ€”and they ensure that consumers and businesses have access to financial services. This capacity to address local needs is fundamental to a strong and stable financial system. To community bankers, customers are much more than their credit score or their annual income, and small businesses are far more than their most recent revenues. By extending credit and offering specialized products and services that meet the needs of their borrowers, these banks empower communities to thrive.

We live in an exciting time, when the face of banking is changing faster and perhaps more fundamentally than it ever has. The first digital banks appeared on the scene about 25 years ago. Since then, financial technology has evolved rapidly. Technology puts more information in the hands of both the customer and the bank. As financial institutions succeed in digitizing more of their offerings, customers are able to monitor cash flows, make direct payments, understand changes in their credit scores, track spending, and budget more easily. Technologies like predictive analytics, when supported with appropriate consumer protections, can improve bank services and performance by enabling continuous tailoring of the customer experience. It also helps banks identify products that are best suited for their customers and their business model and strategy. For those account holders who are willing, an analysis of spending habits may indicate that they could benefit from services they hadn't yet considered.

But successful innovation is not just about adopting the latest technologies. Successful innovation has always required strategic vision and creativity. Community banks thrive when they find creative ways to serve their communities, using everything they know to build relationships, offer solutions, and make lending decisions. We need only look to the performance of community banks during the financial crisis to see how well they leverage this local knowledge and their relationships to make lending decisions.

After the onset of the crisis, community banks' superior loan quality resulted in lower aggregate delinquency and charge-off rates compared to the largest banks. This superior performance was widespreadâ€”community banks in the vast majority of states outperformed the largest banks in this way.1

Even today, community banks continue to perform with distinction. In the third quarter of 2019, community banks' pre-tax return on average assets was 1.5 percent, marking the highest pre-tax return on assets ratio reported by community banks since 2006. Asset quality also remains strong for community banks and is better than for larger banks. The community bank net charge-off rate for total loans and leases was less than 0.2 percent at the end of the third quarter 2019. Let me state that againâ€”the net charge-off rate was less than 0.2 percent, less than half of the industry average. Community bank capital levels remain at continued high and increasing levels. Community banks reported a total risk-based capital ratio of nearly 16 percent, as compared to the industry average of less than 15 percent. This type of performance positions the community banking sector for continued success this year and well into the future, helping ensure the preservation of the community bank model for future generations of Americans.

Community banks understand their borrowers and their specific needs. While technology continues to evolve and change the way we live and bank for the better, it still cannot by itself fulfill that unique and vital role.

Today, there are more than 4,800 community banks in the United States.2 Nearly 80 percent of these have assets totaling less than $500 million, with roughly 40 full- and part-time employees, on average. The vast majority of these community banks are financially strong, and are the backbone of the towns and cities they serve, providing loans to individuals and businesses in the local area. But as customers' needs and goals evolve, community banks will need to evolve to meet them.

The successful integration of financial technology into the community bank business model is proving to be enormously valuable to enable community banks to enhance the services they've already proven they can deliver effectively. Access to technology and services to meet customer needs is critical to ensuring community banks remain vibrant.

For the remainder of my remarks, I will focus on my vision for creating pathways to responsible community bank innovation. In particular, I will discuss the promise and the challenges that smaller banks face in identifying, integrating, and deploying transformative new technologies, and I will offer some ideas for how the Federal Reserve can help community banks find and manage their relationships with service providers.

Clearing a Path for Innovation
Community banks have always been innovators, but rapid technology adoption is challenging for banks of all sizes. In most cases, realizing the potential that technology offers requires community banks to obtain services from other companies or products from core service providers, which I will refer to collectively as third-party providers. As I noted earlier, banks with less than $500 million in assets employ roughly 40 people on averageâ€”nowhere near the number required to exhaustively develop, test, and manage every element of novel technologies. In my discussions with bankers, they note that the process of selecting, initially vetting, and continuing to evaluate third-party service providers is onerous and presents obstacles to successful innovation.

I agree that the cost of complying with some of our regulations and expectations for third-party relationships can pose an outsized and undue burden on smaller banks. These compliance costs are in some instances disproportionate to bank size, complexity, risk, and capacity and can be the same for a bank with $10 million in assets and a bank with $10 billion in assets. Further, expectations of due diligence when applied to a potential fintech partner may require more financial history or information than that partner can provide.

Due diligence for new third-party relationships, even those that are not start-ups, can require a community bank to collect and analyze a significant amount of complex information. Also, the annual monitoring that is required adds an additional significant and ongoing burden. The process for managing the annual collection and review of the financials, audit results, and other operational compliance materials for multiple vendors can take weeks of time for several employees. Bank employees must review thousands of pages of documentation, and the workload per vendor can be the same for all banks, regardless of their asset size and number of employees. And as someone who has been involved in this compliance work, I know that it's not as if other responsibilities can waitâ€”community bank employees often wear several hats. Community banks must weigh the benefit of any third-party relationship against the additional work required to evaluate the third party. And even when new product offerings emerge from service providers that already serve the bank, contract terms can be complicated to adjust, adding to the costs of obtaining technologies, which may ultimately be prohibitive. Flexible core systems are important for this reason. Collaboration between a bank and its core system provider is critical to ensure that technology solutions can be integrated quickly and cost effectively within the core system.

Creating the Right Regulatory Environment
Responsible innovation, especially for smaller institutions, requires two key aspects: a clear idea of how the technology serves a bank's strategic objectives and a regulatory environment that supports innovation. I will touch today on the important interplay between these factors, and in particular, the role that regulators can play in creating a regulatory environment that is conducive to innovation, preserves the safety and soundness of the financial system, and protects consumers. As regulators, we need to ensure that banks uphold sound risk-management practices. Yet we also have information that can help community banks meet those standards. We should closely examine opportunities to share that knowledge, subject to appropriate safeguards, in order to support innovation.

Responsible innovation begins with a bank's strategy. Banks need to identify their goals and then look to identify the kinds of products and services that can help them move forward to implement that strategy. In the past, I have spoken about the importance of considering the impact of new technologies and finding ways to leverage them, if a bank feels that it fits into its business model and strategy. For community banks, a decision to embrace a new technology or innovation is almost always synonymous with third-party engagement.

Regulators and supervisors can contribute to an environment where banks are empowered to achieve these strategic objectives, simplifying and clarifying the process of third-party selection, due diligence, and monitoring.

A bank may decide that its business model should evolve, and that offering a new product or partnering with a fintech company will help it position itself for future growth. This decision is an essential one, but what comes next? This is a new world for most community banks, and supervisors and regulators can lend their expertise to those banks seeking to navigate the unfamiliar landscape.

To that end, the Federal Reserve recently launched a web page on innovation and announced several upcoming Reserve Bank events. The innovation page on our website (www.federalreserve.gov/innovate) is intended to be a one-stop shop for supervisory information, publications, research, and international work that is related to technology innovation. Most importantly, the web page also facilitates interaction with Federal Reserve System specialists, to enable bankers and tech industry participants to submit questions about all aspects of technology in the financial services industry, or to request an in-person meeting. Essentially, to open a dialogue.

We have also launched a series of Innovation Office Hours events hosted by Reserve Banks. These events incorporate panel discussions and face-to-face meetings for bankers with regulators and supervisors, which are intended to be a resource for both state member banks and fintech companies seeking partnerships with or offering services to banks. During these meetings, banks that attend the office hours will have an opportunity to share specific projects or proposed partnerships and learn about how regulators approach and consider risk management in those contexts. Regulators can also share their observations about effective implementation and risk-management practices across the sector. Equally important, the events provide regulators an opportunity to hear directly from banks and fintech companies about challenges to innovation. The office hours events will also include a panel discussion on innovation topics that will help to provide additional insights into new financial technologies. Our first office hours event will be held at the Federal Reserve Bank of Atlanta later this month. Additional events are planned later in the spring and throughout the rest of the year. These are an important opportunity for us to learn, and I look forward to hearing your feedback on these events.

I'd like to turn next to another step in this processâ€”the selection of a third-party provider. This step can be challenging given a lack of information about potential partners when many firms, and their product offerings, are new. Notably, in the 2019 National Survey of Community Banks, community bankers voiced a desire for more transparency into third-party service providers, to inform decisions about whether to enter into contracts with these providers and the type of contract that may be appropriate.3

In this regard, I believe the Federal Reserve should consider several possible steps. First, we should explore the possibility of publishing the list of service providers subject to supervision by the agencies. This could provide a starting point for community banks by sharing information about the types of companies providing services to a large number of financial institutions.

Second, I believe we should increase transparency around our own practices. Through the banking agencies' service provider program, we regularly conduct examinations for and produce independent evaluations of certain providers of critical services. These exams are focused on risk management, audit, and internal controls. The Fed and other agencies have the statutory authority to oversee third-party providers that serve the banks they supervise. Providers that represent a significant level of risk to their clients are part of an interagency supervisory program. The agencies make the outcomes of those exams available to banks that are clients of a supervised service provider.

I believe we can take a step further with increasing transparency on our supervisory program by making information that may be useful about our supervision of key service providers available to banks. This could take a number of forms, such as being more transparent about who and what we evaluate. Of course, moving forward in these areas requires careful consideration and interagency collaboration, and I have asked our staff to work with other agencies to develop and propose workable options for giving banks the benefit of the knowledge that supervisors have about their potential providers in an appropriate manner.

Once banks seeking to innovate have navigated the selection process and identified a partner, they now face a complicated due-diligence process. I believe that regulators and supervisors have a role in easing the burden of that process for community banks in several respects.

First, we could help by implementing clear third-party guidance that is consistent across all regulatory agencies. The Federal Reserve is in the process of working with the other banking agencies to update our third-party guidance. I believe that the banking agencies should all have consistent expectations for third-party relationships, and that the Federal Reserve should, as a starting point, move toward adopting the Office of the Comptroller of the Currency's (OCC) guidance. It is incredibly inefficient to have banks and their potential fintech partners and other vendors try to navigate unnecessary differences and inconsistencies in guidance across agencies.

Second, this guidance should allow banks to conduct shared due diligence on potential partners. If several banks use the same third-party service provider and are open to collaborating, they should be allowed to pool resources instead of duplicating one another's work.

Third, the guidance should explain what due diligence looks like for a potential fintech partner, because the standards applied to other third parties may not be universally applicable. For example, many fintech companies lack the kind of long financial history associated with more traditional bank vendors. Perhaps a fintech company has been around for only a few years. On its own, the fact that a bank cannot evaluate more than five years of the company's financials should not necessarily stop this company from being considered as a partner. Every bank has different objectives, and potential partnerships are not one-size-fits-all. Regulators should especially support partnerships that combine the strengths of community banks and fintech companies, which have a track record of success. The guidance should reflect some supervisory flexibility, and not impede prudent, strategic partnerships between community banks and potential partners.

Fourth, in order to give community banks a better picture of what success in due diligence looks like, and where it begins and ends, I also believe that we should release more information on its necessary elements. This change would provide clarity and assist community banks in completing their work. In particular, I believe that regulators can provide more clarity on the types of questions that should be asked of a prospective third-party provider and our view of a satisfactory answer. Such a handbook would not only have the benefit of increasing transparency for community banks but could also be beneficial for fintech companies that hope to become third-party providers.

Finally, I know from experience that once due diligence has concluded, the evaluation of third-party relationships is not over. As I noted earlier, monitoring can take weeks of work every year for community bank employees. To be sure, this work is an important part of risk management. But I believe regulators and supervisors have a role to play in ensuring that the burden is tailored to bank size, risk, complexity, and capacity. Knowing the burden that third-party monitoring can present to employees of the smallest banks, I have encouraged Federal Reserve staff to consider options for further tailoring our expectations for community banks with assets under $1 billion in this area. We should be mindful that when we apply the same expectations to banks with starkly different asset sizes, we are creating the same workload for a bank with about 30 employees as for a bank with roughly 180 employees, even though their resources and risk profiles are quite different.

Closing Remarks
To conclude, I believe that we can create a regulatory environment in which community banks are empowered to innovate, in which supervisors leverage their own knowledge to help banks understand what to look for in a service provider. It's a regulatory environment in which guidance is clear and supervisors are appropriately flexible, and due diligence and third-party evaluations are appropriately scaled.

Every bank must decide for itself whether and how to adapt their business models to new technologies, but supervisors and regulators can facilitate innovation at a few key milestones on that path forward. First, supervisors and regulators can serve as a resource for banks navigating the financial technology landscape for the first time, and make subject-matter experts accessible. Second, we can make the process of selecting a partner appropriate for a bank's business strategy a more informed one, by being more transparent about our own supervisory program for certain service providers. Third, we can facilitate vetting of potential partners by allowing shared due diligence, providing in our guidance specific expectations for partnerships with fintech companies, and publishing a handbook of sound practices in due diligence. Finally, we can reduce burden on banks as they continue to evaluate risk at third-party providers, by rightsizing our expectations and sharing more information about our supervisory program. Capacity, in addition to complexity and size, should be considered as we continue to tailor supervisory expectations.

As we work toward the environment I described, communication between regulators, supervisors, banks, and fintech partners must be frequent, and confusion about compliance requirements must not be an impediment to banks who wish to partner with third parties. I believe the steps I have laid out today are a promising beginning to making this regulatory environment a reality.

I would like to thank the organizers for the opportunity to speak to you today. My plan is to address some topical and important issues, some of which are quite technical but technicalities that I think can have significant consequences.1 After providing my thoughts on where the economy and monetary policy are now, I will turn to what we can expect from monetary policy in the years to come.

Changes in the economic environment since the financial crisis, including an apparent decline in the equilibrium interest rate, have complicated the conduct of monetary policy as we work to achieve our dual mandate of maximum employment and stable prices. The Federal Open Market Committee (FOMC) is currently undertaking a review of its monetary policy strategy, tools, and communication practices to make sure we are best positioned to confront the challenges ahead. Since the Committee is still actively discussing the review, I have no intention of front-running the results. Instead, I would like to address a separate but not unrelated topic, the interaction of bank supervision and regulation with monetary policy, and how supervision and regulation might work to make monetary policy implementation more effective in the current environment, particularly as it relates to a bank's demand for reserves.2

But first, let me start with a brief take on the current economic outlook. There is much to be encouraged by in the nation's current economic performance even as some notable risks require careful monitoring.

The labor market continues to perform remarkably well, providing a key pillar of support for the rest of the economy. The unemployment rate is at a 50-year low. The labor force participation rate has been steady for some time now despite continued predictions for its decline premised on an aging population moving into retirement. Taken together, low unemployment and steady participation have boosted the employment-to-population ratio, which has finally surpassed its pre-crisis level. A strong labor market, in turn, supports a healthy pace of consumption growth and the economy more generally.

There has been some public discussion about what constitutes a tight labor market. I am in the camp that believes that some additional slack remains in the market, particularly in the potential for higher labor force participation. I have spoken for some time about my confidence that a strong labor market will continue to draw in workersâ€”and lead other workers to delay retirement or otherwise remain in the labor forceâ€”and, so far, I remain optimistic.

Although I feel good about the outlook, a few developments give me pause. Significantly, investment continues to be weak, declining over the course of 2019. Increasing the capital stock and investing in new technologies are important for productivity growth, rising living standards, and the economy's long-run growth rate, so reversing the recent downward trend is essential for the overall health of the economy.

In part, the fall in investment likely reflects business concerns over the pace of global growth and risks to the outlook. In particular, 2019 was a bad year for economic growth among U.S. trading partners, and, as a consequence, our exports suffered. Recently, I have been encouraged by the progress in U.S. trade negotiations. I am hopeful that the recently signed phase-one deal with China will boost U.S. exports and lead to considerable reduction in the uncertainty that has been weighing on businesses, as will the continued progress in enacting the trade agreement with Canada and Mexico.

While the recent progress on trade should boost business confidence, the outbreak of the Wuhan coronavirus introduces a new element of uncertainty. In addition to the human toll, the virus also threatens significant economic disruption, particularly for China and its neighbors, as workers and consumers stay home and normal activities are otherwise disrupted. It is too early to say what the full economic effect of the outbreak will be, and this situation will require careful monitoring.

In summary, I remain optimistic about the outlook, but I am also highly aware that some notable risks still threaten growth, both overseas and at home.

A few words on inflation. Both headline and core inflation, as measured by the price index for personal consumption expenditures, or PCE, came in at 1.6 percent in December, somewhat below the FOMC's 2 percent objective. This deviation does not worry me that much, in part because I expect inflation to move back to target over the medium term, in part as some unusually low readings in early 2019 pass out of the data. Already, various trimmed price indexes are running much closer to 2 percent.

Monetary Policy Considerations
I view the current stance of monetary policy as appropriate given the economic outlook and relatively muted inflation pressures. Policy is in a good place to support continued economic growth, strong labor market conditions, and inflation returning to target. That said, now is a good time to be thinking about the challenges that monetary policy is likely to face in the coming years.

One important development, as I mentioned at the start, is that interest rates at home and abroad have declined significantly from their pre-recession levels. Policymakers, economists, and market participants see much of this decline as reflecting a permanent fall in the equilibrium rate of interestâ€”that is, the level of the federal funds rate that keeps the economy at full employment with stable inflation in the longer run. For example, in the most recent Summary of Economic Projections compiling the individual forecasts of FOMC participants, the median estimate of the longer-run federal funds rate, a value that incorporates policymakers' assessments of the equilibrium rate, was 2-1/2 percent, down from 4-1/4 percent in early 2012.3

All else being equal, a fall in the equilibrium rate of interest lessens the scope for the FOMC to cut rates in response to a significant economic downturn, as the distance to zero shrinks. In the absence of compensating policy actions, this situation may aggravate economic downturns. Thankfully, in practice policymakers have several additional tools to ease financial conditions and support the economy.

One such tool is forward guidance: By credibly conveying to the public that policymakers will likely pursue a path for the policy rate that is lower than previously anticipated, policymakers can put downward pressure on longer-term interest rates. In addition, policymakers can implement policies such as large-scale asset purchases (LSAPs) that affect the size and composition of the balance sheet: By purchasing longer-term securities in the open market, the Federal Reserve reduces the quantity of such assets available for purchase. The increased scarcity tends to raise the price of these securities and depress their yields. Balance sheet policies can put further downward pressure on longer-term yields by reinforcing the credibility of the forward guidance if these policies are seen as a signal that policymakers intend to keep the policy rate low for an extended period.4

The FOMC used both forward guidance and balance sheet policies in response to the financial crisis. Some observers argue that forward guidance and asset purchases fully offset the shortfall in policy accommodation caused by a lack of space to cut interest rates further, so that the limits on the Fed's policy rate did not ultimately constrain our policy response to the financial crisis. Other observers see these policy tools as having had, at best, a small positive effect on the economy. Somewhere between these two extremes, the majority view is that forward guidance and balance sheet polices likely made up for some, though not all, of the shortfall.5

The experience gained with these tools during and after the financial crisis will likely facilitate their prompt and effective deployment in future episodes when there is no longer space for further cuts in the policy rate.

In retrospect, many of the potential negative effects associated with forward guidance and LSAPs did not materialize. In particular, inflation remained contained, and longer-run inflation expectations did not become unanchored. A large balance sheet did not prevent the FOMC from raising the policy rate when it deemed such action was appropriate.

To gain the full benefit of our toolkit, it will be important to continue to communicate clearly about our willingness to use all of our tools in future downturns.6 The greater the public confidence that policymakers will use these tools in response to episodes when the ability to cut the policy rate is constrained, the more real longer-term interest rates will systematically decline in response to negative economic developments, providing an automatic stabilizer to the economy. Moreover, public confidence in the FOMC's ability to react to economic downturnsâ€”even when the policy rate is very lowâ€”will support the resilience of longer-term inflation expectations at levels consistent with the FOMC's objective. Keeping inflation expectations anchored will in turn further support the FOMC's ability to lower real interest rates if the economy were to weaken substantially.

Balance Sheet Policies and Reserve Demand
Taking stock, I note that one approach to the constraints on policy imposed by the current low level of interest rates is to make what were previously unconventional toolsâ€”balance sheet policies and forward guidanceâ€”as conventional as possible. Although I fully support the FOMC's current plan to purchase Treasury bills and increase the size of the balance sheet in the very short term, over the longer-term, I believe that the viability of balance sheet policies is enhanced if we can show that we can meaningfully shrink the size of the balance sheet relative to gross domestic product following a recession-induced balance sheet expansion. In effect, I believe that balance sheet policies are more credible if we can show that there is not a persistent ratcheting-up effect in the size of the Fed's asset holdings.

Of course, the balance sheet is not going back to pre-crisis levels, when the size was primarily determined by the Fed's currency liabilities. As the FOMC announced in January of 2019, the Committee intends to implement monetary policy in an ample-reserves regime.7 With that approach, control over the level of the federal funds rate and other short-term interest rates is exercised primarily through the setting of the Federal Reserve's administered rates and is not, over the longer term, reliant on frequent and large open market operations. The Committee also reiterated that it would assess the level of reserves most consistent with efficient and effective monetary policy implementation. Questions about this level have moved to the forefront following market dislocations and money market pressure amid a temporary, but pronounced, reduction in the supply of reserves as a result of an increase in our nonreserve liabilities in September. Indeed, this episode has been cited by a number of firms and analysts who estimate that the amount of reserves consistent with an ample framework was higher than they previously had thought.

Following the mid-September volatility, the Committee stated that it would seek to maintain, over time, a level of bank reserves at or above the level that prevailed in early September, a level that we believe is sufficient to operate an ample-reserves regime. Looking ahead, I judge that it is reasonable that we ask ourselves whether it may be possible to operate with a lower level of reserves and remain consistent with the ample framework.

I will spend the remainder of my time exploring possible means to enhance the efficiency of our monetary policy implementation, including reserve provision, through adjustments to our existing regulatory and supervisory regime. In particular, I will focus on liquidity regulation and supervision as well as interactions with monetary policy tools. And I will suggest a policy-based approach to some of the issues I identify.

Before going into more detail about what I mean, let me emphasize that I will be touching on some issues that the Federal Reserve is in the process of observing and evaluating and, in some cases, may be far from reaching any final decisions. As such, my thoughts on these issues are my own and are likely to evolve, benefiting from further analysis and monitoring of bank behavior and financial markets over time.

Let me take a step back to highlight some of the key features of the current liquidity regulation and supervision regime, features that have resulted in significant increases in the liquidity resilience and risk-management capabilities of our largest institutions. Taken together, these featuresâ€”including the Liquidity Coverage Ratio (LCR), Regulation YY's enhanced prudential standards, and resolution planningâ€”require large firms to demonstrate that they hold sufficient liquid assets to meet outflows in stressed scenarios and in resolution.

In short, we expect firms to manage their liquidity risk prudentlyâ€”to self-insureâ€”so they can withstand the types of runs we saw during the crisis without relying on taxpayer support. This outcome has contributed to a more resilient financial system and leaves taxpayers in a much better place today.

Following the implementation of these requirements, large banks have more than doubled their buffers of liquid assets. More specifically, our largest banks have significantly increased their holdings of assets known as Level 1 high-quality liquid assets (HQLA). Level 1 HQLA includes central bank reserves, Treasury securities, and Ginnie Mae securities.

As discussed in the original design for the LCR, all forms of Level 1 HQLA are treated as substitutes. There is no preference for reserves versus, say, Treasury securities in the calculation of the ratio.

Despite the regulatory text's equal treatment of Level 1 HQLA, we know that reserves have special characteristics when it comes to stress. Even though the Treasury market is the most liquid in the world, in an actual stress event, banks would still need to take steps to monetize Treasury securities to meet cash outflows.

However, it may be difficult to liquidate a large stock of Treasury securities to meet large "day one" outflows. For firms with significant capital market activities, wholesale operations, and institutional clients (such as hedge funds), this scenario is not just theoretical. In the global financial crisis, several firms experienced outflows exceeding tens of billions of dollars in a single day.

The LCR does not capture these on-the-ground realities. But supervision does. Under Regulation YY's enhanced prudential standards, large firms are required to conduct internal liquidity stress tests (ILSTs). Supervisors expect firms to estimate day-one outflows and to ensure that their liquidity buffers can cover those outflows without reliance on the Federal Reserve. For firms with large day-one outflows, reserves can meet this need most clearly.

Yet it is worth remembering that a principal reason for the Federal Reserve's creation was to facilitate the movement of reserves when needed from banks with an excess reserve position to those in need of reserves.8 Indeed, it is the reason we are called the Federal Reserve. I do not think that is a fact of purely historical interest. Excessive friction in the movement of cash in the financial system was likely a contributor to the market dislocations of last September. In that regard, I think it is worth considering whether financial system efficiency may be improved if reserves and Treasury securities' liquidity characteristics were regarded as more similar than they are todayâ€”that is to say, that reserves and Treasury securities were more easily substitutable in the context of liquidity buffers. To be clear, the ideas I will discuss do not involve any decrease in banks' liquidity buffers. Rather, I want to explore options that would maintain at least the level of resilience today while also facilitating the use of HQLA beyond reserves to meet the immediate liquidity needs projected in banks' stress scenarios.

My suggested options are grounded in the principle that the Federal Reserve has an important role in providing liquidity to depository institutions. Today this role is played by the discount window, through which Reserve Banks provide fully collateralized loans to healthy institutions. While the range of eligible collateral for such liquidity provision is very broad, it may be worthwhile to focus for the moment on the Federal Reserve's potential to provide liquidity that is collateralized only by Level 1 HQLA. With firms posting Level 1 assets as collateral, the Fed would be well positioned to provide liquidity to bridge the monetization characteristics of HQLA securities versus reserves. Acknowledging this potential role in stress scenarios, the Fed may promote efficient market functioning while assuming very limited risk. If firms could assume that this traditional form of liquidity provision from the Fed was available in their stress-planning scenarios, the liquidity characteristics of Treasury securities could be the same as reserves, and both assets would be available to meet same-day needs.

There are a variety of ways we could achieve this outcome. One approach would be to adopt a policy whereby firms are permitted to assume that the discount window can be used in their liquidity-planning stress scenarios under certain conditions.

The discount window is meant to be used by healthy banks when it is needed. While there has long been discussion about how the discount window is "broken" because of stigma about using it, we know it is still an important part of firms' contingency planning and preparations. Banks currently pledge over $1.6 trillion in collateral to the discount window, which means that banks have gone to the trouble of working with their local Reserve Bank to make sure they have access to the window, if needed, and they have set aside a portion of their balance sheets as collateral to do so.9

We have also already publicly clarified in the 2019 resolution planning guidance that firms can assume discount window access in their Title 1 plans if they can meet the terms for borrowing, such as recapitalizing the bank subsidiary.10

We could build on this approach by also allowing firms to rely on the discount window in their ILSTs as a means of monetizing, for example, Treasury securities in their scenarios. This approach would acknowledge a role for the discount window in stress planning, improve the substitutability of reserves and Treasury securities in firms' HQLA buffers, and maintain the overall level of HQLA that firms need to hold. Such an approach could improve the efficiency of monetary policy implementation, as firms might show a greater willingness to reallocate to Treasury securities, reducing reserve demand and improving market functioning.

An additional advantage of such an approach is that it could further improve the incentives of firms to be prepared to use the discount window, which we already know is important for contingency planning. If firms were to include the discount window in their plans for how they will weather a stress scenario, they would also need to demonstrate to supervisors that they are prepared to use it to ensure that their plans are credible. Also, with this approach, we would not need to set up any new programs. In connection with this, we are closely examining how international counterparts treat the equivalent of discount window access in their banks' stress-planning scenarios.

Another approach could be to set up a new program or facility: For example, there has been much discussion among market participants, as well as policymakers, about the potential benefits of setting up a standing repurchase agreement, or repo, facility for banks and how such a facility could improve the substitutability of reserves and Treasury securities for these firms.11 While this option is still of interest, there may be benefits to working first with the tools we already have at our immediate disposal.

Finally, some firms and industry observers have pointed to the surcharge for global systemically important banks, and its partial dependence on year-end inputs, as potentially exacerbating the issues I have discussed today. Preliminary analysis suggests that changing those inputs to averages may be helpful. If we were to propose that change, it would not alter the stringency of the surcharge. As such, this option is something that we are actively considering.

In summary, there are great benefits to safety and soundness and to financial stability for firms holding sufficient buffers of HQLA to meet potential outflows in stress. I am not proposing any changes to this basic framework. What I am proposing is that we can potentially improve the efficiency of monetary policy implementation by improving the substitutability of reserves and Treasury securities through adjusting our expectations for firms in stress-planning scenarios. There are a variety of approaches we could take, but I think the Fed has a role to play.

I want to thank Darrell Duffie for inviting me to discuss the future of payments.1 Digitalization is enabling consumers and businesses to transfer value instantaneously, technology platforms to scale up rapidly in payments, and new digital currencies to facilitate these payments. By transforming payments, digitalization has the potential to deliver greater value and convenience at lower cost. But there are risks. Some of the new players are outside the financial system's regulatory guardrails, and their new currencies could pose challenges in areas such as illicit finance, privacy, financial stability, and monetary policy transmission.

Given the stakes, the public sector must engage in order to ensure that the payments infrastructure is safe as well as efficient and fast, assess whether regulatory perimeters need to be redrawn or new approaches are needed in areas such as consumer data and identity authentication, and explore the role of central bank digital currencies in ensuring sovereign currencies stay at the center of each nation's financial system. These issues are complicated and consequential. I will only touch on them today in the spirit of sketching out an agenda for the public sector along with the private sector and research community.

Digital Players
Technology firmsâ€”from BigTechs to FinTechsâ€”are driving the digital transformation of payments. Not only are the new players bringing innovation to the way payments are made between businesses and consumers and peer-to-peer, but they are bringing new business models that bundle payments with other activities in novel ways.

Payments have traditionally been a service provided by trusted intermediaries such as banks. The operations of banks and some related financial service providers, such as card companies, are subject to regulatory oversight for sound risk management. Banks offer important consumer protections, including deposit insurance, error resolution, and fraud protection. In addition to providing payments services, banks generally provide credit, with deposits providing stable funding. Many banks rely at least in part on legacy technology.

In contrast, BigTechs tend to be established platforms with massive user networks that provide payments in support of core nonfinancial servicesâ€”ranging from commercial transactions to social engagement to mobile apps to search engines. In China, the majority of consumers and businesses participate in two mobile payment networks, Alipay and WeChat Pay, which by some accounts handled more than $37 trillion in mobile payments in 2018.2 BigTechs and FinTechs typically leverage cloud-based platforms and computing power, along with mobile applications, often to provide different combinations of services and enhanced user experiences. They generally benefit from network effects: the more users they have, the more convenience and benefit new users derive from joining. These network benefits may be augmented by leveraging economies of scale and scope in user data for a host of purposes, from prioritizing which information is pushed to users to allocating and pricing credit to sharing reviews.

The entrance of BigTech and FinTech into payments may drive competition, enhance product offerings, and lower transactions costs. It has the potential to enhance financial inclusion by expanding the number and diversity of ways people gain access to financial services and by creating more consumer friendly offerings. A Federal Deposit Insurance Corporation (FDIC) study found that 8.4 million households are unbanked and an additional 24 million are underbanked.3 These households often rely on more-expensive means of payments, including nonbank providers and bank money orders. Many have smartphones, which could facilitate access to payment apps.

The entry of big technology networks into payments brings risks as well as benefits. Statutory and regulatory protections on bank accounts in the United States mean that consumers can reasonably expect their deposits to be insured up to a limit; their banks to be held to strong data security standards; many fraudulent transactions to be the liability of the bank; transfers to be available within specified periods; and clear, standardized disclosures about account fees and interest payments to be readily available. Consumers may not appreciate that nonbank providers might not provide the same protections. Further, the integration of payments with a variety of consumer services that rely intensively on user data raises the urgency of questions surrounding data security, how consumers' financial data are used, and the circumstances under which the data are disclosed to third parties.

Unlike many foreign central banks, the Federal Reserve does not have plenary authority over payment systems. No federal agency does. The Federal Reserve has broad authority over payment systems that are designated as systemically important by the Financial Stability Oversight Council or that are chartered as entities for which the Federal Reserve is the primary supervisor. These authorities cover two large-value interbank payment systems but no retail payment system to date. The banking agencies may oversee certain aspects of a nonbank payment system to the extent there is a bank nexus, under the Bank Service Company Act, or bank affiliation, under the Federal Deposit Insurance Act.4 However, this oversight will be quite limited to the extent that nonbank players reduce or eliminate the nexus to banks, such as when technology firms develop payments services connected to digital wallets rather than bank accounts and rely on digital currencies rather than sovereign currencies as the means of exchange.

Given the growing role of nonbank technology players in payments, a review of the nation's oversight framework for retail payment systems could be helpful to identify important gaps. A good place to start may be contrasting the U.S. oversight framework for retail payment systems with other jurisdictions. Many foreign central banks, for example, have explicit authority for general retail payments oversight.5 Moreover, most jurisdictions require that payment systems obtain a license and/or registration before commencing operations. A 2018 World Bank study found that the large majority of jurisdictions have some sort of license and/or registration requirement for mobile money platforms, payment card networks or switches, or clearinghouses.6 The United States requires registration of a money transmitter at the federal level for purposes of Bank Secrecy Act/Anti-Money-Laundering compliance, but it does not require broader federal oversight of payment system operators.7

In contrast to other jurisdictions where there is explicit responsibility for broad regulation of payment systems, the Federal Reserve's role as an operator has instead long formed the basis of the U.S. approach to promoting accessible, safe, and efficient payments. Since the Federal Reserve Banks opened for business around the country in 1914, as directed by the Congress, they have provided payment and settlement services in competition with private-sector providers.

Real-Time Infrastructure
So let's turn to our retail payments infrastructure, which touches every American. While new players are making important contributions to the digital transformation of payments, it is critical that consumers and businesses can achieve the same speed and efficiency using their trusted deposit account providers with the safety and security they have come to expect. To make this possible, it is vital to invest in real-time retail payments infrastructure with national reach.

Today, it can take a few days to get access to your funds. A real-time retail payments infrastructure would ensure the funds are available immediatelyâ€”to pay utility bills or split the rent with roommates, or for small business owners to pay their suppliers. Immediate access to funds could be especially important for households on fixed incomes or living paycheck to paycheck, when waiting days for the funds to be available to pay a bill can mean overdraft fees or late fees that can compound. Similarly, for small businesses, getting immediate access to funds from a sale in order to pay for supplies can be a game-changer.

The latest evolution in the payments infrastructure is faster payments, in which the payment message is transmitted and funds are settled between banks and made irrevocably available to recipients in real (or near-real) time. Consistent with the real-time and anytime nature of faster payments, settlement takes place in real time on a 24-hour, seven-day basis.

We are committed to closing the gap between the transaction capabilities in the digital economy and the underlying payment and settlement capabilities. Recognizing that consumers and businesses across the country want and expect real-time payments, and the banks they trust should be able to provide this service securely, this summer, the Federal Reserve announced that it is building its first new payments rail in more than forty yearsâ€”the FedNow Service.8 FedNow will facilitate end-to-end faster payment services, increase competition, and ensure equitable and ubiquitous access to banks of all sizes nationwide.

Together, the Clearing House's RTP and FedNow are moving the U.S. banking system to real-time retail payments. These systems will enable consumers and businesses to settle retail transactions in real time, at any time, and allow them to manage their money with greater flexibility. RTP and FedNow should significantly increase the speed and efficiency of the U.S. payment system.

Given the importance of safety in faster payments, providing access to more than one real-time payment service for back-up purposes will enhance resiliency. The Federal Reserve has always had a vital role in the payment system by providing liquidity and operational continuity in times of stress, and FedNow will extend this role into the real-time retail payments market.

The addition of FedNow should also provide a neutral foundation for private sector innovation in developing end-user services. Some stakeholders noted that a single provider that is owned and operated by one segment of the payment industry may focus on a limited set of use cases instead of the full breadth of possible use cases for faster payments.

The FedNow team is already hard at work determining initial business requirements. The comment period for the Federal Register notice seeking public input into FedNow features and designs closed in November, and we are analyzing the nearly 200 letters submitted.9 We understand the urgency among stakeholders to launch FedNow quickly with features that support safe, efficient, and ubiquitous faster payments.

Digitalization of Currencies
Digital transformation of payments extends not only to the systems and players, but also to the medium of exchange.10 The existing payments system combines central bank money, commercial bank money, and certain kinds of nonbank private money, which provide a medium of exchange based on the U.S. dollar as a unit of account. By contrast, some technology players have payment systems based on their own digital currency rather than the sovereign currency. Depending on their design and scale, private digital-currency-based payment systems could magnify concerns surrounding illicit activity and consumer risk, while potentially creating challenges for the public sector's ability to safeguard financial stability and use monetary policy to buffer the economy.

Central bank money is important for payment systems because it represents a safe settlement asset, allowing users to exchange central bank liabilities with confidence in their acceptance and reliability. In the United States, central bank money is composed of paper currency and money held in deposits at the Federal Reserve Banks. Commercial bank moneyâ€”money held in deposits at commercial banksâ€”is widely used because consumers and businesses trust that the money they deposit with a commercial bank can be converted, on demand, into a claim on another commercial bank's money or currency. This confidence owes in large part to bank deposit insurance and the fact that commercial banks are supervised and regulated.

Nonbank private money based on the U.S. dollar as the unit of account exists on a smaller scale for a variety of consumer uses, particularly in closed-loop payment systems like prepaid cards and digital wallets. In some cases, such nonbank private assets may have value only within the network, while in other cases, the issuer may promise convertibility to a sovereign currency, such that this becomes a liability of the issuing entity. Although various federal and state laws establish protections for users, issuers of nonbank money are not regulated to the same extent as banks, the value stored in these systems is not insured directly by the FDIC, and consumers may be at risk that the issuer will not be able to honor its liabilities. To provide a sense of the scale, PayPal Holdings Inc. had customer accounts that totaled $22.5 billion as of September 30, 2019; Walmart had roughly $1.9 billion in deferred gift card revenue as of October 31, 2019; and Starbucks reported $1.6 billion in stored-value card liabilities as of September 2018â€”more than the deposits at many banks.11

In contrast, cryptocurrencies introduce separate units of account. Built using distributed ledger technologies, cryptocurrencies typically allow for peer-to-peer payments without the need for a financial intermediary. The private sector is exploring uses of distributed ledger technologies to create a wide range of payment instruments, some that are designed to resemble traditional commercial bank money, some that look similar to Bitcoin, and some that have attributes more similar to securities. Cryptocurrencies vary across multiple attributes, including whether the arrangement is open to everyone or only approved entities and whether they are intended for general-purpose use or for wholesale use.

One important design choice is whether a digital currency is account-based or token-based. From an accounting perspective, there is an account structure for the asset owner and for the asset itself. Individual accounts could take the form of traditional account structures of commercial banks or be pseudo-anonymous. The accounting of the asset itself could take the form of debiting and crediting account balances or tracking of specific "tokens." Another key design consideration is the method for authenticating the asset ownerâ€”to open an account and to make transactions. Traditionally, identity authentication is done by the account provider, but new tools, such as biometrics, may be required for decentralized systems. A third important design variant is convertibility. Private-sector digital currencies vary in important ways with regard to whether they are linked in a legally binding way to a sovereign currency.

A decade ago, Bitcoin was heralded as a new kind of digital money that would serve as a store of value, means of exchange, and unit of account delinked from any sovereign currencies without the need for centralized governance. Bitcoin has not achieved widespread acceptance as a means of payment or unit of account because of its extreme volatility, as well as limited throughput capacity, unpredictable transaction costs, limited or no governance, and limited transparency.

Stablecoins were designed specifically to overcome the volatility of first-generation cryptocurrencies by tying the digital currency to an asset or basket of assets, such as commercial bank deposits or government-issued bonds. Unlike first-generation cryptocurrencies, they may be issued by a central entity and rely on third-party institutions for some aspects. But even within this broad class of digital currencies, stablecoins vary widely in their underlying reference assets and the associated "exchange rate," the ability to redeem the stablecoin claims for the underlying assets, and the extent to which a central issuer is liable for making good on redemption rights.

Because Facebook has an active user network of one-third of the global population, the company's Libra global stablecoin project has imparted urgency to the debate over what form money can take, who or what can issue it, and how payments can be recorded and settled. Any stablecoin project with global scale and scope faces a core set of legal and regulatory challenges. Cryptocurrencies already pose risks associated with fraudulent activity, consumer losses, and illicit activity, and these could be magnified by a widely accepted stablecoin for general use. Not only is it not clear what protections or recourse consumers would have with regard to their global stablecoin transactions and balances, but it is also not clear how much price risk consumers will face in cases where they do not appear to have claims on the stablecoin's underlying assets.

If not managed effectively, liquidity, credit, market, or operational risksâ€”alone or in combinationâ€”could affect financial stability, triggering a loss of confidence and run-like behavior. The precise nature of the risk would be driven in part by how the stablecoin is tied to an asset (if at all), the underlying legal arrangements, and the features of the asset itself. For smaller economies, there may be material effects on monetary policy from private-sector digital currencies as well as foreign central bank digital currencies. In many respects, these effects may be the digital version of "dollarization," with the potential for a faster pace and wider scope of adoption.

Central Bank Digital Currencies
The prospect for rapid adoption of global stablecoin payment systems has intensified calls for central banks to issue digital currencies in order to maintain the sovereign currency as the anchor of the nation's payment systems. In a Bank for International Settlements survey of 66 central banks, more than 80 percent of central banks report being engaged in some type of central bank digital currency (CBDC) work.12 The motivations for this work range from payments safety and robustness for advanced economies to payments efficiency for emerging economies. The latest survey suggests there is greater openness to issuing a CBDC than a year ago, and a few central banks report that they are moving forward with issuing a CBDC. Building on the tremendous reach of its mobile payments platforms, China is reported to be moving ahead rapidly on plans to issue a digital currency.13

Given the dollar's important role, it is essential that we remain on the frontier of research and policy development regarding CBDC. Like other central banks, we are conducting research and experimentation related to distributed ledger technologies and their potential use case for digital currencies, including the potential for a CBDC. We are collaborating with other central banks as we advance our understanding of central bank digital currencies.

In assessing CBDC in the U.S. context, there are policy and design issues to explore, as well as legal considerations. It is important to consider whether a new form of digital central bank liability might improve the payment system, taking into account the innovations offered by the private sector. We would need to consider whether adding a new form of central bank liability would reduce operational vulnerabilities from a safety and resilience perspective. Another consideration is whether a CBDC would reduce complexity in payments, improve end-to-end processing, or simplify recordkeeping. With regard to cross-border payments, it is important to consider what would be required in terms of cross-border cooperation for CBDCs to address current frictions and reduce costs.

It is also vital to consider the implications for the broader financial system of the issuance of a CBDC. In light of considerations of privacy and guarding against illicit activity, issuance of a digital currency would raise important questions about what kinds of intermediaries might provide CBDC transaction accounts for consumers. While some proposals are centered on commercial bank intermediaries, others propose new types of intermediaries that might develop with a narrow focus on payments. New types of intermediaries in turn could create a need for new types of accounts and new forms of oversight.

Related to this, the design of any CBDC needs to address important questions surrounding financial stability. A variety of approaches have been put forward to address the potential run risk associated with the ability to convert commercial bank deposits into CBDC with a simple swipe.14

There are also important legal considerations. It is important to understand how the existing provisions of the Federal Reserve Act with regard to currency issuance apply to the CBDC. It is also important to consider whether CBDC would have legal tender status, depending on the design. While the legal framework is well-established with regard to the rights and protections for Federal Reserve notes in the current system, it is untested for new instruments such as CBDC and, more generally, other digital currencies. A different approach may be necessary to ensure that holders of CBDC have appropriate protections, including privacy rights, fraud protection, digital identity safeguards, and data protection.

These are some of the issues that would need to be addressed before deciding to issue a CBDC in the United States. Some of the motivations for a CBDC cited by other jurisdictions, such as rapidly declining cash use, weak financial institutions, and underdeveloped payment systems, are not shared by the United States. Physical cash in circulation for the U.S. dollar continues to rise because of robust demand, and the dollar plays an important role globally. We have a robust and diverse banking system that provides important services, along with a widely available and expanding variety of digital payment options.

Agenda Ahead
The digitalization of currencies and payments is being driven by technology players that are bringing new business models to this space and fresh attention to age-old questions. While the potential for seamlessly integrated and lower-cost transactions brings important benefits, digitalization also brings risks. In the United States no less than in other major economies, the public sector needs to engage actively with the private sector and the research community to consider whether new guardrails need to be established, whether existing regulatory perimeters need to be redrawn, and whether a CBDC would deliver important benefits on net.



It's a great pleasure to be with you today at the ABA Banking Law Committee's annual meeting. I left the practice of lawâ€”and immersion in the company of lawyersâ€”closing in on 20 years ago now, but there have been many times during my long sojourn among businessmen and economists that I have reflected with fondness and some nostalgia on the famous adage of Harrison Tweed (the "Tweed" of Milbank, Tweed, a reformer of the bar, the "most democratic of aristocrats," and the last man to unironically wear a cape in the lobby of the Chase Manhattan Plaza) which most of you can no doubt recite by heart: "I have a high opinion of lawyers. With all their faults, they stack up well against those in every other occupation or profession. They are better to work with or play with or fight with or drink with than most other varieties of mankind." Speaking here feels a lot like coming home.

This afternoon, I would like to talk with you about the outwardly mundane but increasingly consequential topic of bank supervision. Twenty years ago, when I would have been among your number at this meeting, this would have been my cue to pull out my Blackberry and start checking my emails. The structure and content of regulation was both intellectually interesting and professionally meaningful; I considered bank supervision, by contrast, as both too workaday and too straightforward to merit the commitment of much legal horsepower or personal attention. I could perhaps have been excused by the callowness of youth, yet it was a common view at the time. Having now been immersed for the last two years both in the practice of supervision and in the complementary relationship between the regulatory and supervisory processes, I realize that this wasn't true then, and is certainly not true now. It is not a drafting accident that the Dodd-Frank Act gave my position at the Federal Reserve the title of Vice Chairman for Supervision. Notwithstanding the extensive reform of bank regulation after the crisis, which has had much consequence for the industry (most of it salutary) it is the process of examination and supervision that constitutes the bulk of our ongoing engagement with the industry and through which our policy objectives are given effect.

This division of labor is important for lawyers and policymakers to think about deeply because the processes of regulation and supervision are necessarily different in crucial respects. Regulation establishes a binding public framework implementing relevant statutory imperatives. Because a rule is designed to apply generally, rules must be based on general principles intended to achieve general aims, rather than reverse-engineered to generate specific effects for specific institutions. Given their general applicability, there must be a general process for all those with an interestâ€”industry, academics, citizens, Congressâ€”to have notice of, and opportunity to comment on all rules, ensuring that all potential effects and points of view are taken into account in the rule's crafting. And given their general function, rules must be clear and public: Those affected must know what to expect and what is expected.

Supervision, by contrast, implements the regulatory framework through close engagement with the particular facts about particular firms: their individual capital and liquidity positions, the diverse composition of their distinct portfolios of assets, their business strategies, the nature of their operations, the strengths and weaknesses of their management. Much of the granular information used by supervisors is, accordingly, proprietary and confidential, and many of their judgments and decisions are closely tailored to specific circumstances.

Given the strong public interest in the safe, sound, and efficient operation of the financial industry and the potential for hair-raising and widespread adverse social consequences of private misjudgment or misconduct in that industry, close and regular supervision of this sort can help us all sleep restfully. Yet, the confidential and tailored nature of supervision sits uncomfortably with the responsibilities of government in a democracy. In the United States, we have a long-standing, well-articulated framework for ensuring that regulations conform with the principles of generality, predictability, publicity, and consultation described above. Supervisionâ€”for good reason, in my viewâ€”is not subject to this formal framework. But it is currently not subject to any specific process constraint promoting publicity or universality. This leaves it open to the charge, and sometimes to the fact, of capriciousness, unaccountability, unequal application, and excessive burden.

Here, then, is a conundrum. We have a public interest in a confidential, tailored, rapid-acting and closely informed system of bank supervision. And we have a public interest in all governmental processes being fair, predictable, efficient, and accountable. How do we square this circle? In my time with you today, we will not do more than scratch the surface of this question. It is a complex and consequential issue that, for decades now, has received far too little attention from practitioners, academics, policymakers and the public. Evaluating this question will be a significant focus of mine going forward, and I hope that there will be much discussion in many fora from which we at the Fed, and at other regulators, can learn. So today, I simply want to open the exploration of some these conceptual issues, and then offer some specific suggestionsâ€”by no means comprehensiveâ€”on some obvious and immediate ways that supervision can become more transparent, efficient, and effective.

The Importance of Transparency
Let me begin by delving a little more deeply into the distinction between regulation and supervision and the process applicable to both. In delegating to agencies such as the Fed the significant power to write regulations, Congress has codified a regulatory process that emphasizes transparency. This process was born in the 1930s, in the tumult of government expansion that was the New Deal, when Congress began a decade-long debate over how to manage the new regulatory state. The result, the Administrative Procedure Act (APA), was, I should note, developed with the active involvement of the American Bar Association. The APA continues to serve as the basis for the public disclosure and participation required for agency rule-writing and for the judicial review affected parties are guaranteed to challenge rules.

This transparency is intended to prevent arbitrary, capricious, and thus ineffective regulation by inviting broad public participation and mandating a deliberate public debate over the content of proposed rules. One obvious purpose of this transparency is to provide clarity and predictability: it helps make clear how agencies are considering exercising their discretion. The significant process protections in laws such as the APA are also meant to ensure fairness. The wisdom behind this approach is that fairness both helps bring forth more considered and effective regulations and builds respect for and adherence to the law, which is essential for enforcement. Transparency is central to our ability to assert that our rules are fair.

Not everything that government does, however, can be accomplished in exactly the same way that regulations are written. One of these things is bank supervision.

Bank Supervision
Banks are subjected to supervision, in addition to regulation, as an additional form of government oversight because of their complexity, opacity, vulnerability to runs, and indispensable role in the economy, enabling payments, transmitting monetary policy, and providing credit. The government provides a safety net to banks in the form of deposit insurance, and in return, banks are subject to government oversight that mimics some of the monitoring that the private sector would provide, absent the government safety net. The bank regulatory framework sets the core architectural requirements for the banking system, but it isn't enough to set the rules and walk away like Voltaire's god. The potential consequences of disruption in the financial system are so far-reaching, and the erosion of market discipline resulting from the government safety net sufficiently material, that it is neither safe nor reasonable to rely entirely on after-the-fact enforcement to ensure regulatory compliance. Supervisors are in a good position to monitor individual firms' idiosyncratic risks. And in addition to what they do at individual banks, supervisors monitor for risk that may be building among clusters of banks or across the banking system. These "horizontal" exams across multiple banks help highlight new or emerging risks and help examiners understand how banks are managing these risks.

Through their engagement with banks, supervisors promote good risk management and thus help banks preemptively avert excessive risk taking that would be costly and inefficient to correct after the fact. Where banks fall materially out of compliance with a regulatory framework or act in a manner that poses a threat to their safety and soundness, supervisors can act rapidly to address the failures that led to the lack of compliance or threat to safety and soundness.

This is a crucial point: Supervision is most effective when expectations are clear and supervision promotes an approach to risk management that deters bad behavior and decisions by banks. Clearly communicating those expectations is essential to effective supervision, and in a larger sense, clear two-way communication is the essence of effective supervision. Supervisors rely on banks to be frank and forthcoming, and supervisors in turn can help secure that frankness by explaining what their expectations are and why their expectations are reasonable, not arbitrary or capricious. Greater transparency in supervision about the content of our expectations and about how we form our expectations and judgments can make supervision more effective by building trust and respect for the fairness and rationality of supervision.

I don't believe the Federal Reserve has communicated as clearly as it could with the banks we supervise. More transparency and more clarity about what we want to achieve as supervisors and how we approach our work will improve supervision, and I have several specific proposals.

Broadly speaking, these actions fall into three categories: (1) large bank supervision, (2) transparency improvements, and (3) overall supervisory process improvements.

Large Bank Supervision
Last fall, we completed a cornerstone of the recent banking legislation to tailor our rules for regional banks. This was entirely consistent with a principle at the heart of our existing work: Firms that pose greater risks should meet higher standards and receive more scrutiny. Our previous rules relied heavily on a firm's total assets as a proxy for these risks and for the costs the financial system would incur if a firm failed. This simple asset proxy was clear and critical, rough and ready, but neither risk sensitive nor complete. Our new rules employ a broader set of indicators, like short-term wholesale funding and off-balance-sheet exposures, to assess the need for greater supervisory scrutiny.

That said, the composition of our supervisory portfolios has not yet been aligned with our recent tailoring rules. For example, the Large Institution Supervision Coordinating Committee (LISCC) portfolio includes all Category I firms, which have the greatest risk profile, along with certain Category II and Category III firms, which are less systemic. Other Category II and Category III firms, on the other hand, are supervised under our large and foreign banking organizations (LFBO) portfolio.

Since the crisis, we have been giving significant thought to the composition of our supervisory portfolios, and, in particular to whether and how we should address the significant decrease in size and risk profile of the foreign firms in the LISCC portfolio over the past decade. Because of these changes, which I will describe in more detail momentarily, I believe there is a compelling justification to make changes today to the composition of the foreign banks in the LISCC portfolio.

Separately and in keeping with the goal of transparency, I think it is important that all the Fed's supervisory portfolios have a clear and transparent definition. Today nearly all of our supervisory portfolios have such a crisp and clear formulaic definition specified in the public domain, but the LISCC portfolio does not. My goal is to develop, prospectively, a clear and transparent standard for identifying LISCC firms. My preferred approach for achieving this objective would be to align the LISCC portfolio with our recent tailoring categorizations. I believe we should draw the LISCC line to coincide with Category I. The justification for this line-drawing is that Category I firms pose the most systemic risk and require the most supervisory attention. In this state of the world, Category II and III firms would remain subject to heightened supervisory standards that are commensurate with their risk profile.

Allow me to draw out what this approach could mean for the foreign banks that currently are in the LISCC portfolio. Since 2010, these four banks have significantly shrunk their U.S. footprint, and their U.S. operations are much less risky than they used to be. Since 2008, the size of the LISCC FBOs' combined U.S. assets has shrunk by about 50 percent, and they have reduced the assets at their broker-dealers from a peak of $1.9 trillion in 2008 to $340 billion today, a reduction of over 80%. In addition, the estimated systemic impact of the LISCC FBOs today is much smaller than the U.S. GSIBs. The average method 1 GSIB score of the combined U.S. operations of the LISCC FBOs is less than a quarter of the average GSIB score of the six non-processing U.S. GSIBs.

Thus, if any foreign banks move out of the LISCC portfolio based on this de-risking, they would move into the LFBO portfolio, where they would be supervised alongside other foreign and domestic firms with similar risk profiles. Notably, this change in supervisory portfolio would have no effect on the regulatory capital or liquidity requirements that currently apply to the four LISCC FBOs. Similarly, the change would not result in a loss of insight into the activities of these firms.

In the same spirit, I think we should consider publishing the internal procedural materials that the Fed uses to supervise the LISCC firms, sometimes referred to as the Program Manual. The Manual contains a description of the main supervisory processes for identifying risks and our approach for addressing them. Publishing the Manual would help the public and the banks better understand why we take the actions that we take as supervisors and would demystify some of our processes. If we took these two simple stepsâ€”defining LISCC firms and publishing the Program Manual that governs our supervisory approachâ€”it would go a long way in helping to make our supervisory practices more understandable and accessible without undermining supervisory effectiveness.

Let me now turn to the ratings framework that applies to all large holding companies. A firm's supervisory rating, which is confidential, is important because it affects things such as the firm's ability to engage in mergers and acquisitions and to enter new lines of business. Just over a year ago, the Board began implementing a new ratings framework for large holding companies called the large financial institutions (LFI) ratings framework. The LFI ratings framework focuses on three components of a firm's operations: capital, liquidity, and governance and controls. We inaugurated the LFI ratings framework for LISCC firms in January 2019 and for other large holding companies at the beginning of this year.

As we gain more experience with LFI, we will be paying close attention to how the new rating system is working and whether it is achieving its intended purpose. There are two features of the ratings system that I will be particularly interested to monitor, and which may well require adjustment. These are the embedding of qualitative "risk management" standards in the capital and liquidity components of the ratings (as opposed to standardized quantitative measures of capital and liquidity adequacy) and the ascetic principle by which a firm's "well managed" status is determined by its lowest component rating, no matter how good the bank is at everything else.

Regarding our stress tests under the Comprehensive Capital Analysis and Review (CCAR), I continue to look for ways to make the tests more transparent without making them game-able and without diluting their potency as a supervisory tool. I will mention three of these transparency-enhancing ideas. First, I expect that we will continue to provide more transparency on the models used in CCAR. We started providing improved transparency on models last year, and as I have previously said, we will remain on that path until we have released substantial details on all of our key models. We also continue to consider ways to increase the transparency around the scenarios we use in CCAR, including, for example, by modifying our scenario design policy statement to provide greater transparency on the design of the global market shock component of the stress tests.

Second, I expect that as part of the stress capital buffer, we will give banks significantly more time to review their stress test results and understand their capital requirements before we demand their final capital plan. Firms are currently permitted to revise and resubmit their capital plans after receiving their stress test results. But it is done on a short timeframe, and allowing additional time would produce better results without in any way reducing the stringency of the stress tests. Fundamentally, I think banks will be better able to do intelligent capital planning if we provide them with their complete set of regulatory capital requirements before we require submission of a capital plan.

Third and finally, we continue to look for ways to reduce the volatility of stress-test requirements from year to year. We are considering a number of options, such as averaging outcomes over multiple years or averaging the results of the current year's stress test with the results of one or more previous years. Again, the goal here is not to make the tests less strenuous but to give banks a greater opportunity to plan for them and to meet our expectations ex ante rather than through an ex post remedial process.

Transparency Improvements
The next three actions I'm proposing also relate to improved transparency, and they would improve our processes for supervising all banks. The first would be to create a word-searchable database on the Board's website with the historical interpretations by the Board and its staff of all significant rules. Regulatory interpretations by Board staff have grown piecemeal over the decades and haven't consistently been treated as the valuable resource they are. The Board's website has select interpretations of many laws but does not provide a comprehensive, user-friendly collection of regulatory interpretations, FAQs, and commentary. This project will require some effort of course, as well as vigilance to keep the interpretations up to date, but I believe that the end result will be well worth it.

The second of these transparency actions would be putting significant supervisory guidance out for public comment. The Board already invites comments on its regulations, as required under the APA, and regularly invites comment on some supervisory guidance and statements of policy. This practice of seeking comment on guidance leads to better, more informed supervision and better engagement by banks. I would like the Board to seek comment on more supervisory guidance going forward.

Third and finally, as another improvement related to guidance, I support submitting significant supervisory guidance to Congress for purposes of the Congressional Review Act. Currently, the Fed does this for rules but not guidance. I support doing so for significant guidance because significant guidance, though nonbinding, can still have a material impact on bank behavior. I believe this step would enhance the Fed's accountability and help build support for supervisory guidance.

Overall Supervisory Process Improvements
The last category of proposals includes five areas of improvement that all relate to what we call the "supervisory process"â€”how we go about conducting our responsibilities. Like my other suggestions, these are all rooted in common sense with a view toward maintaining firm and fair supervision.

The first is to increase the ability of supervised firms to share Federal Reserve confidential supervisory information (CSI) with employees, affiliates, service providers, and other government agencies to promote greater compliance with laws and facilitate the response to enforcement actions. We have received feedback that our rules can prevent banks from sharing CSI with a wide variety of relevant parties who need to know this information in order to help the bank remediate identified supervisory issues. We issued a proposal last year to address this shortcoming in our CSI rules, and I expect the Board will be able to issue a final CSI rule later this year.

The second process improvement is having the Board adopt a rule on how we use guidance in the supervisory process. I would expect the rule to state that the Board will follow and respect the limits of administrative law in carrying out its supervisory responsibilities. In particular, consistent with the September 2018 interagency statement on guidance, we would affirm the sensible principles that guidance is not binding and "non-compliance" with guidance may not form the basis for an enforcement action (such as a cease-and-desist order) or supervisory criticism (such as a Matter Requiring Attention (MRA)). This rule would be binding on the Board and on all staff of the Federal Reserve System, including bank examiners.

The third and fourth process improvements relate to supervisory communication. The third improvement is to restore the "supervisory observation" category for lesser safety and soundness issues. This approach would provide supervisors with a toolâ€”supervisory recommendationsâ€”for continuing to raise concerns about less pressing supervisory matters while focusing a bank's attention on the most urgent matters, those that would receive MRAs. We removed this category of supervisory commentary in 2013 to better focus bank management on deficiencies found during the supervision process. (By way of comparison, both the FDIC and OCC retained this tool.) On reflection, I think there is value in supervisory observations. They allow an examiner to give notice about a supervisory concern even if that concern has not risen to the level of an MRA.

The fourth process improvement would be limiting future MRAs to violations of law, violations of regulation, and material safety and soundness issues. MRAs are supervisory communications that identify areas where banks are out of compliance with applicable legal standards or otherwise are engaged in practices that create substantial safety and soundness risks. MRAs identify the source of the compliance failure, deficiency, or safety and soundness weakness and generally include an expected timeframe for remediation. MRAs are not legally binding and are not enforcement actions.

Nevertheless, MRAs carry weight because they can affect a bank's supervisory rating. In limiting MRAs to legal violations and significant supervisory concerns, we would take care to clearly define the breadth of what constitutes a "material safety and soundness issue." This distinction is important as a matter of fairness. Banks should be able to understand the line between MRAs significant enough to affect the bank's supervisory rating and less significant matters that don't affect a bank's supervisory rating but raise concerns that should be considered by banks. Greater fairness contributes to greater supervisory effectiveness. Together, the third and fourth process improvements would be calibrated to improve communications so that banks can focus on remediating key weaknesses while maintaining awareness of emerging ones. Ultimately, a bank that promptly corrects its material safety and soundness weaknesses will be better able to serve its customers and intermediate credit through a range of scenarios, including under stress.

The final process improvement is to make routine our existing practice of having an independent review of important supervisory communications and guidance documents. We want to make sure that our supervisory communications, including MRAs, focus on violations of law and material safety and soundness issues and that these communications don't mistakenly give the impression that supervisory guidance is binding. We already closely scrutinize MRAs issued to the LISCC firms and in horizontal reviews of other large domestic and foreign banks. This extra scrutiny is a sensible practice that should be regularized and expanded across our supervisory portfolios.

With respect to prospectively assessing future guidance, the key goals here would include reassessing the scope of key guidance documents, removing inappropriate bright lines from guidance, and removing any mandatory language from guidance. I will discuss each of these goals in turn.

As I mentioned, the Board adopted a final tailoring rule last year that adjusted the regulatory standards applicable to banks, based on their risk profile. I think it would be useful for us to review our guidance in light of this tailoring exercise, such as guidance on stress testing and capital planning, and to update the scope of guidance where appropriate.

Regarding bright lines, bright lines tend to carry the implication that the standard they are delineating is binding. For this reason, rules often include bright lines so that it is clear how to stay in compliance with the rule. Putting bright lines in guidance, even when the bright line is phrased as a "should" rather than as a requirement, blurs the line between guidance and rules, and for this reason, it is a practice we should avoid.

For the same reason, it is inappropriate to put mandatory language in guidance. This practice can create the same distortions as the use of bright lines.

Conclusion
Obviously, the incremental changes to our supervisory processes described above do not completely answer the question with which I began my remarks today: How can we square the public interest in agile supervision with the public interest in transparency and accountability? This should be an ongoing question of high priority, both at the Fed and more broadly among those who care about our system of financial regulation. Equally obviously, however, these suggestions would strengthen our practice of supervision and increase the vigor and credibility of our supervisors.

The changes to supervision since the crisis have made the financial system stronger and more resilient than it was before. The incremental changes I have outlined, to increase transparency, accountability, and fairness, would make supervision more efficient and effective, and our financial system stronger and more stable.

Few sectors are as central to the success of our economy and the lives of American families as housing. If we include the amount families spend on shelter each month as well as the construction of new houses and apartments, housing generates about 15 cents out of every dollar of economic activity. As homebuilders, you set the foundation that supports the work of architects, bankers, electricians, carpenters, plumbers, furniture makers, and many others. In our time together today, I'd like to discuss the outlook for housing at the national level and also look at the labor force and credit challenges facing your industry.1

Let me start with just a few words about the overall economic picture. I'm pleased to say that the U.S. economy is currently in a good place, and the baseline outlook of participants on the Federal Open Market Committee (FOMC) is for continued moderate growth in gross domestic product (GDP) over the next few years. Unemployment is the lowest it has been in 50 years, and FOMC participants expect it to remain low. Inflation has been muted and is expected to rise gradually to the FOMC's 2 percent objective.

One of the most remarkable features of the current economic expansion has been the vitality and resilience of the U.S. job market. More than 22 million jobs have been created since the low point for employment at the end of the last downturn, and the pace of job gains has been amazingly consistent. Until this expansion, even in good times, scarcely a year went by without at least one month when payrolls shrank. Yet during the past 10 years, we haven't had a single month with a decline in the overall number of jobs. I should note that I would not necessarily consider a single month of job losses as saying much about the direction of the economy. But the unbroken string of job gains that we have experienced during this recovery highlights how our economy has kept humming along during this past decade, weathering the occasional lull. Let me also add here that, as good as the national numbers for the job market look, things seem even better here in the Kansas City area, where job growth has been steady and the unemployment rate has consistently run around 1 percentage point below the national averageâ€”at last count, it was 2.8 percent.

Let me now turn to the main topic of my talk today. My colleagues and I at the Federal Reserve pay close attention to developments in the housing sector, in part because it has historically been such an important driver of economic growth. In the national economic data, the part of GDP that includes homebuilding activity is referred to as residential fixed investment. This measure summarizes a variety of housing-related activities, including spending on the construction of new single-family and multifamily structures, residential remodeling, real estate brokers' fees, and a few other smaller components.

If we look at the growth of residential fixed investment in periods since World War II that are defined as economic expansions, we see that this broad category has increased at an average rate of around 7 percent per year, faster than the roughly 4 percent pace of GDP growth in those same periods. And, as many of you know from experience, the opposite is true as wellâ€”that housing activity tends to experience relatively large declines in economic downturns. In particular, residential fixed investment declined an average of about 15 percent annually during periods defined as recessions, compared with an average annual rate of decline in GDP of just 2 percent in those same periods.

These numbers illustrate that residential fixed investment is particularly sensitive to where we are in the business cycle. The strong economy we are experiencing now has an obvious upside for the housing sector: A robust job market translates into higher incomes, greater confidence, and more people looking to buy a new home or considering whether to make a change from their current home.

Yet even though the financial crisis and the bursting of the real estate bubble occurred more than a decade ago, all of us here are no doubt aware of the lasting imprint that those developments left on the housing market. On an annual basis, both new and existing home sales did not increase again until 2012, and they remained at modest levels for several years thereafter. Given the large and persistent inventory overhang of unsold homes in the aftermath of the crisis, the construction of new homes was also sluggish for many years into the recovery.

Part of the weak recovery in the housing market during the first few years of this expansion can be traced to extremely tight mortgage credit conditions. Despite the fact that the Fed slashed interest rates and kept them low for many years, many households were underwater on their existing mortgages, with more owed on their housing than their homes were worth, while others were unable to obtain a loan to finance a new purchase. As a result, housing demand remained very weak for an extended period.

Another factor that played a role in the slow housing recovery was the low rate of household formation, which dropped significantly during the recession and remained low for most of the following decade. Much of this drop was due to a larger share of young people continuing to live with their parents, though this is not unusual when the economy is weak and jobs are hard to find.2

In the past few years, though, we have seen some encouraging signs that the broader strength in the economy has eased these housing market headwinds. Along with ongoing improvements in households' balance sheet conditions, mortgage credit conditions appear to be less of a constraint for creditworthy borrowers. I should add that housing activity is also being supported by interest rates that remain quite low by historical standards, with the fixed rate charged on a 30-year mortgage now below 4 percent, substantially lower than the rates observed just before the last recession. As you well know, activity in the housing sector is highly sensitive to interest rates and other factors that have a powerful effect on the overall cost of owning a home.

In addition, amid the strong job market of the past few years, we have seen a rise in the rate at which young adults are moving out of their family homes and forming households of their own. Even so, millions of young adults are still living with their parents who likely wouldn't have been before the crisis. While their reasons for doing so are probably varied, there is potential for many more individuals to shift back to forming new households.

Although the effects may evolve slowly, the higher rate of household formation will eventually result in higher demand for housing and encourage further increases in homebuilding. Home sales have been rising in recent years, the percentage of homes that are vacant has been falling, and inventories of both new and existing homes for sale have drifted back down to relatively low levels. In fact, at this point, the residential real estate market is quite tight in some areas of the country and by enough that I have heard that the volume of home sales is being restricted by the low inventory of homes on the market.

The most recent housing data have been encouraging: Both new and existing home sales moved up strongly in the second half of 2019, and traffic of prospective buyers in new homes for sale and expected sales within the next six months have approached all-time highs. Permits for new residential construction, which had been sluggish early last year, recently moved up to highs for this expansion. In all, the national indicators suggest a positive growth outlook for the housing sector over the next several quarters.

Before I conclude, I'd like to address two challenges currently facing the housing sector. The first relates to the difficulties that some employers face, including homebuilders, in finding and retaining qualified and skilled workers. To provide some context, the national data show that the unemployment rate in the private construction industry is now well below the rate we observed in the early 2000s, a time when the housing market was booming. In addition, the ratio of job vacancies to unemployment in the construction industryâ€”a measure of labor market strengthâ€”shot up to historic highs at the end of 2018, and it has remained near those levels. These indicators confirm what I have been hearing from construction industry employers during my visits to different parts of the countryâ€”it's extremely difficult to find and hire workers, skilled or otherwise.

In response to these hiring-related challenges, we have seen a renewed and broad focus on workforce development initiatives by the public and private sector, a development we have followed closely at the Federal Reserve. I recently heard a very encouraging presentation from representatives of vocational training organizations about progress they are making in connecting young adults, students, and high school grads with skilled trades. I am hopeful that these efforts, along with a continued strong job market, will encourage more people to joinâ€”or, in some cases, rejoinâ€”the construction trades.

The second challenge I want to highlight relates to the declining presence of community banks in the consumer real estate mortgage market. As regulatory burdens have risen, many community banks have significantly scaled back their lending or exited the mortgage market altogether. These developments concern me for several reasons. Home mortgage lending has traditionally been a significant business for smaller banks, and the decline in this business threatens a part of the banking industry that plays a crucial role in communities. Bankers who are present and active in their communities know and understand their customers and the local market better than lenders outside the area. Because of their local knowledge and customer relationships, they are often more willing to help troubled borrowers work their way through difficult times.

These two challenges notwithstanding, I remain optimistic about the outlook for housing. I expect construction to continue advancing to meet the underlying expansion in housing demand from population growth and the strong economy. In addition, low interest rates will continue to be a key factor supporting growth in housing activity. As reported in the latest Summary of Economic Projections, released in December, most FOMC participants see the current target range for the federal funds rate as likely to remain appropriate this year as long as incoming information remains broadly consistent with the economic outlook I described earlier.

In closing, let me say that I would also appreciate hearing what is on your minds. As a policymaker, I particularly value opportunities to travel outside of Washington to hear your perspectives on the national and local economies. These conversations improve our work at the Fed by helping us make better-informed decisions.

Thank you for the opportunity to join you bright and early on this January 2020 Thursday morning. As some of you may know, I am a longtime member of the Council on Foreign Relations and have attended and participated in many such events over the past 20 years, although I will point out that in my previous visits to the dais, I was in the somewhat less demanding position of asking the questions rather than answering them. I am really looking forward to this conversation, but I would like first to share with you some thoughts about the outlook for the U.S. economy and monetary policy.1

The U.S. economy begins the year 2020 in a good place. The unemployment rate is at a 50-year low, inflation is close to our 2 percent objective, gross domestic product growth is solid, and the Federal Open Market Committee's (FOMC) baseline outlook is for a continuation of this performance in 2020.2 At present, personal consumption expenditures (PCE) price inflation is running somewhat below our 2 percent objective, but we project that, under appropriate monetary policy, inflation will rise gradually to our symmetric 2 percent objective. Although the unemployment rate is at a 50-year low, wages are rising broadly in line with productivity growth and underlying inflation. We are not seeing any evidence to date that a strong labor market is putting excessive cost-push pressure on price inflation.

Committee projections for the U.S. economy are similar to our projections at this time one year ago, but over the course of 2019, the FOMC shifted the stance of U.S. monetary policy to offset some significant global growth headwinds and global disinflationary pressures. In 2019, sluggish growth abroad and global developments weighed on investment, exports, and manufacturing in the United States, although there are some indications that headwinds to global growth may be beginning to abate. U.S. inflation remains muted. Over the 12 months through November, PCE inflation was running at 1.5 percent, and core PCE inflation, which excludes volatile food and energy prices and is a better measure of underlying inflation, was running at 1.6 percent. Moreover, inflation expectations, those measured by both surveys and market prices, have moved lower and reside at the low end of a range I consider consistent with our price-stability mandate.

The shift in the stance of monetary policy that we undertook in 2019 was, I believe, well timed and has been providing support to the economy and helping to keep the U.S. outlook on track. I believe that monetary policy is in a good place and should continue to support sustained growth, a strong labor market, and inflation running close to our symmetric 2 percent objective. As long as incoming information about the economy remains broadly consistent with this outlook, the current stance of monetary policy likely will remain appropriate.

Looking ahead, monetary policy is not on a preset course. The Committee will proceed on a meeting-by-meeting basis and will be monitoring the effects of our recent policy actions along with other information bearing on the outlook as we assess the appropriate path of the target range for the federal funds rate. Of course, if developments emerge that, in the future, trigger a material reassessment of our outlook, we will respond accordingly.

In January 2019, my FOMC colleagues and I affirmed that we aim to operate with an ample level of bank reserves in the U.S. financial system.3 And in October, we announced and began to implement a program to address pressures in repurchase agreement (repo) markets that became evident in September.4 To that end, we have been purchasing Treasury bills and conducting both overnight and term repurchase operations, and these efforts were successful in relieving pressures in the repo markets over the year-end. As we enter 2020, let me emphasize that we stand ready to adjust the details of this program as appropriate and in line with our goal, which is to keep the federal funds rate in the target range desired by the FOMC. As the minutes of the December FOMC meeting suggest, it may be appropriate to gradually transition away from active repo operations this year as Treasury bill purchases supply a larger base of reserves, though some repo might be needed at least through April, when tax payments will sharply reduce reserve levels.

Finally, allow me to offer a few words about the FOMC review of the strategy, tools, and communication practices that we commenced in February 2019. This reviewâ€”with public engagement unprecedented in scope for usâ€”is the first of its kind for the Federal Reserve. Through 14 Fed Listens events, including an academic conference in Chicago, we have been hearing a range of perspectives not only from academic experts, but also from representatives of consumer, labor, community, business, and other groups. We are drawing on these insights as we assess how best to achieve and maintain maximum employment and price stability. In July, we began discussing topics associated with the review at regularly scheduled FOMC meetings. We will continue reporting on our discussions in the minutes of FOMC meetings and will share our conclusions with the public when we conclude the review later this year.5

Thank you very much for your time and attention. I look forward to the conversation and the question-and-answer session to follow.

Good morning. I am pleased to be here at the Urban Institute to discuss how to strengthen the Community Reinvestment Act (CRA), which is a key priority for the Federal Reserve. The CRA plays a vital role in bringing banks together with community members, small businesses, local officials, and community groups to make investments in their community's future.1 That is why we are committed to getting CRA reform done right.

The Origins and Purpose of the CRA
Any successful reform must be grounded in the origins of the CRA and its ongoing importance to low- and moderate-income (LMI) neighborhoods. The CRA was one of several landmark pieces of legislation enacted in the wake of the civil rights movement intended to address inequities in the credit markets. By passing the CRA, Congress aimed to reverse the disinvestment associated with years of government policies and market actions that deprived lower-income areas of credit by redliningâ€”using red-inked lines to separate neighborhoods deemed too risky.2 By conferring an affirmative and continuing obligation on banks to help meet the credit needs in all of the neighborhoods they serve, the CRA has not only prompted banks to be more active lenders in LMI areas, but also important participants in multisector efforts to revitalize communities across the country.

Pursuant to guidance from the Board of Governors, each of our Federal Reserve Banks houses a group of dedicated community development professionals and CRA examiners to help banks meet their CRA obligations. We are proud of our work in familiarizing banks with the CRA's provisions, introducing banks to potential partners in their communities, and convening conferences to disseminate research and best practices.3

The CRA plays a vital role in the ecosystem supporting economic opportunity in LMI communities in both rural and urban areas. Rather than direct funds to specific projects, the CRA encourages banks to engage on the priorities identified by local leaders and more broadly serve credit needs of small businesses and residents of these communities. By being inclusive in their lending and investing, banks help their local communities to thrive, which in turn benefits their core business. The recognition of this mutually beneficial relationship between banks and their local communities is one of the core strengths of the CRA and the reason our effort to revise the CRA regulations must focus on local needs and stakeholder input.

What Have We Learned from Stakeholders?
For several years, the federal banking regulators have been asking stakeholders for input on strengthening the CRA regulations to help banks better meet the credit needs of the local LMI communities they serve and more closely align with changes in the ways financial products and services are delivered. We also have heard calls from banking and community organizations for the use of metrics to provide greater upfront clarity about evaluation standards. We have heard that branches remain as important as ever to their local communities, even as the growth of mobile and online services has extended the geographic area that banks are serving.4 The one message we have heard most consistently is that banks and community organizations alike value the activities they undertake under the auspices of the CRA and have invested considerable time and effort in the associated processes and reporting.5 For that reason, stakeholders have asked the regulators to take care as we contemplate changes to the CRA.6

If the past is any guide, major updates to the CRA regulations happen once every few decades. So it is much more important to get reform right than to do it quickly. If we only have one opportunity for a few decades, I want to make sure CRA reform is based on the best analysis and ideas and the broadest input available. It is critical to analyze carefully the likely effects of any proposed changes on credit access and community development in LMI communities, as well as any additional reporting and procedural burdens for banks.

Last year, we set out several principles to guide our work on CRA reform.7 Revisions to the CRA regulations should reflect the credit needs of local communities and work consistently through the business cycle. They should be tailored to banks of different sizes and business strategies. They should provide greater clarity in advance about how activities will be evaluated. They should encourage banks to seek opportunities in distressed and underserved areas. And they should recognize that the CRA is one of several related laws to promote an inclusive financial sector.

Grounding Metrics in Analysis Based on Data
Guided by stakeholder input, we evaluated how to strengthen the regulation by using metrics to provide greater certainty about how activities will be evaluated, while remaining faithful to the core purpose of the CRA to make credit and retail banking services available in local LMI communities. Proposed changes to the CRA regulation must be grounded in analysis and data to avoid unintended consequences.

Because consistent data on CRA-eligible activity were not readily available, our research staff set about creating a database based on over 6,000 written public CRA evaluations from a sample of some 3,700 banks of varying asset sizes, business models, geographic areas, and bank regulators.8 The database includes the location, number, and amount of CRA-eligible loans and investments and the ratings associated with each bank's performance. The data go back to 2005 in order to assess how CRA performance and the associated ratings vary across the economic cycle.

Metrics that Make Sense
So how can we use metrics to provide greater clarity about evaluations? I will sketch out a proposed approach that uses a set of tailored thresholds that are calibrated for local conditions. It starts by creating two tests: a retail test and community development test (figure 1). Broadly speaking, all retail banks would be evaluated under a retail test, which would assess a bank's record of providing retail loans and retail banking services in its assessment areas. Large banks, as well as wholesale and limited-purpose banks, would also be evaluated under a separate community development test that would evaluate a bank's record of providing community development loans, qualified investments, and services.

Using bank and other publicly available data, we would be able to provide a bank with a dashboard indicating how its retail lending activity compares to thresholds for presumptive satisfactory performance that reflect the activity of other lenders and credit demand in the local area. Separate metrics reflecting a bank's assessment area can be provided related to the evaluation of its community development performance.

Dividing evaluations into separate retail and community development tests is important. First, evaluating all retail banks under a stand-alone retail test is important to stay true to the CRA's core focus on providing credit in underserved communities in an assessment area. In contrast, an approach that combines all activity together runs the risk of encouraging some institutions to meet expectations primarily through a few large community development loans or investments rather than meeting local needs.

Second, having separate tests ensures that expectations are tailored for banks of different sizes and business models. Only larger banks would be expected to meet the community development test along with the full retail test. Similar to today, smaller banks would have the option of having their retail banking services and community development activities evaluated in order to achieve an "Outstanding" rating, but it would not be required. Moreover, small banks below some threshold might have the option to be evaluated under the existing methodology.

Third, separate retail and community development tests provide greater scope to calibrate the evaluation metrics to the opportunities available in the market, which can differ for retail lending and community development financing.

After analyzing ways to use metrics across the board, we concluded that the value of retail services and community development services to a local community do not lend themselves easily to a monetary value metric comparable to the monetary value of loans and investments. The value of these services may vary greatly from community to community. It is difficult to monetize this value in a consistent way relative to the value of lending and investment, thus introducing the risk of skewing incentives inadvertently. For example, the services and leadership provided by a small bank located in a rural community may be vital to the success of that community, even if the dollar value of those services is small compared with a branch in a large city. Because of this concern, we are inclined to propose a set of qualitative standards to evaluate retail services within the retail test, and a separate set of qualitative standards to assess community development services within the community development test.

Retail Testâ€”Metrics for Retail Lending
The core of the retail lending test would be to use widely available data to assess two clear objectives: how well a bank is serving LMI borrowers, small businesses, and small farms in its assessment area, and how well a bank is serving LMI neighborhoods in its assessment area. The metrics used to evaluate these two questions would rely on loan counts rather than dollar value in order to avoid inadvertent biases in favor of fewer, higher-dollar value loans.9 The metrics would be evaluated separately for each major product line in a bank's assessment area, which is important to tailor the use of metrics to a bank's business model.

The proposed approach measures a bank's performance in serving the needs of both low- and moderate-income borrowers (and small businesses and small farms) and LMI places in the community. For mortgage loans, an LMI borrower distribution metric would calculate the percentage of a bank's number of loans made to LMI borrowers relative to its overall mortgage originations, and assess this percentage against an assessment area threshold determined by local demographics and the aggregate lending of other in-market competitors. A separate LMI neighborhood distribution metric would evaluate the percentage of a bank's number of loans in LMI tracts to its overall loan count and assess this against a threshold determined by local demographics and the aggregate lending of other in-market competitors.

A bank that meets or exceeds both the LMI borrower and LMI neighborhood thresholds for each of its major product lines would be presumed to have a satisfactory-or-better level of retail lending performance in that assessment area. Using a customized dashboard, each bank could track its own activity against the threshold on an ongoing basis reflecting recent data, eliminating the lengthy uncertainty associated with the current evaluation methodology, which many banks have highlighted as the most important area for reform (figure 2).

Importantly, the CRA database we have constructed confirms that the proposed retail lending metrics correlate well with past ratings of bank performance (figure 3). The specific thresholds that would establish a presumption of satisfactory performance could be informed by current evaluation procedures but need not be set at the same level, and public input will be important.

The retail lending metrics would be tailored to the needs of the local community. This tailoring is not possible with a uniform benchmark that applies to all banks and all communities. The large differences between assessment areas illustrate the importance of tailoring thresholds. For example, in Morgan County, Ohio, LMI families are 49 percent of the population, compared with 31 percent in O'Brien County, Iowa (figure 4). We believe this tailored approach is empirically sound and avoids imposing arbitrary CRA performance measures on a bank and its community. In order to ensure it meets standards of safety and soundness, CRA lending must be evaluated in the context of the characteristics of the bank and its community.

Additionally, the proposed retail lending metric would automatically adjust to changes in the business cycle. As many commenters noted in response to the ANPR, a uniform ratio that does not adjust with the local business cycle could provide too little incentive to make good loans during an expansion and incentives to make unsound loans during a downturn, which could be inconsistent with the safe and sound practices mandated by the CRA statute. Industry commenters also expressed concern that discretionary adjustments to the uniform metric are likely to lag behind the economic cycle and undermine the certainty a metric purports to provide. By contrast, the proposed retail lending metrics are calibrated to contemporaneous changes in market conditions, thereby reducing the risk of providing unsound incentives (figure 5).

Finally, the proposed approach would continue to recognize local context in assessing a bank's CRA performance. If a bank receives the presumption of satisfactory by meeting or exceeding the thresholds, an examiner could consider performance context information, including the bank's responsiveness to the community's needs, in determining whether the bank's performance is outstanding at the assessment area level. Likewise, if a bank does not meet or exceed the thresholds, it would undergo a full examination, as it would currently, and could receive any level of rating, including possibly Outstanding, based on the full range of performance context considerations and clear qualitative criteria. The metrics would be designed to provide greater certainty, while avoiding rigidity.

Retail Testâ€”Evaluating Retail Services
Retail services can be extremely important to LMI communities, although they do not easily lend themselves to consistent, comparable metrics. It makes sense to use qualitative criteria related to the responsiveness of a bank's products and services and its delivery systems, which stakeholders highlighted as being particularly important in LMI areas.

In terms of delivery systems, we recognize the unique and important role that branches play in providing essential financial services to customers, particularly in underserved areas. Banks would be evaluated on their branch and ATM locations and how well they serve customers using online and mobile access channels. Providing a meaningful evaluation of all customer access channels is essential to ensuring that the CRA remains relevant as more banks adopt digital technology.

Recognizing that branches are important community assets, the proposed retail service test would compare a bank's distribution of branches, including any openings or closures, to broader patterns of activity in the region. A recent report on branch access in rural areas found that just over 40 percent of rural counties lost bank branches between 2012 and 2017, with 39 rural communities being "deeply affected" by the loss of more than half of their bank branches.10 In addition to the challenges associated with higher cost and less convenient access to banking services, community leaders described how branch closures diminished their access to important leadership from branch personnel that was important to their community's success.

Community Development Testâ€”Measuring Lending and Investment
Next, let's turn to the community development test for large retail banks, as well as wholesale and limited-purpose banks. The establishment of a separate community development test reflects stakeholder feedback emphasizing that the value of community development finance is distinct and not directly comparable to retail activity. A separate test also allows for a broader area to be taken into account for purposes of community development relative to retail lending.

Our analysis suggests there are a set of metrics that can be compared to appropriately tailored benchmarks to provide greater certainty regarding community development lending and investment. The proposed metric would aggregate loan and investment dollars that are originated or purchased during the evaluation period with the book value of all other community development loans and investments that are held on the bank's balance sheet (figure 6). Reflecting input from banks and community organizations that patient, committed funding has the greatest effect, this approach avoids the incentives under current practice to provide financing in the form of short-term renewable loans in order to receive CRA credit.11

The proposed test would compare the combined measure of a bank's community development financing relative to deposits in its local assessment area to a national average, set differently for rural and urban areas, and a local average in the bank's assessment area. The national comparator would be set differently for metropolitan statistical areas and rural areas to reflect the comparatively lower average levels of financial infrastructure in rural communities (figure 7). The use of a national rural/metro comparator in addition to an assessment area comparator is intended to avoid skewing incentives toward financially dense areas that are already hotly competitive and to reflect the value of community development in underserved areas. The use of these comparators would help provide consistency across evaluations and clarity regarding community development expectations for both banks and communities.

It is also important to recognize that community development financing is often provided in areas that do not neatly fit within a bank's assessment area. Community development financing opportunities are not always easy for banks to identify and often depend on working with local nonprofits or governments to help identify projects and put together the complex financing required to bring them to fruition. Stakeholder feedback emphasized banks' unique advantages in evaluating community development projects in the states and territories where they operate and providing the smaller-scale, more complex, and often more impactful, investments overlooked by institutional investors. For this reason, and to encourage more activity in underserved areas, it makes sense to give consideration to all of a bank's community development activities in a state or territory where it has an assessment area.12

Banks want to know in advance that they will get the benefit of CRA consideration in order to invest the time and effort necessary to evaluate and structure community development loans and investments. For that reason, we are sympathetic to requests for a timely process by which banks can seek conditional examiner review of particular activities before making financial commitments, particularly for activities that revitalize and stabilize targeted areas.

Our analysis suggests a community development finance metric along the lines outlined here will help to ensure greater predictability and consistency in achieving a Satisfactory rating. However, we also want to make sure that these metrics are supplemented with clear, qualitative standards to ensure that small-scale, high-impact community development activities are rewarded, along with a bank's responsiveness to local needs and priorities.

Community Development Testâ€”Evaluating Services
It is also important to evaluate services qualitatively at the assessment-area level as part of the overall community development test. Volunteer and other services provided by banks can provide meaningful support to communities whose value is unlikely to be adequately captured on a comparable basis using aggregative dollar value metrics. In areas with a low density of financial services, a bank officer on the board of local community organizations could provide considerable value to the community that is not accurately reflected by monetizing volunteer hours based on their compensation.

Tailoring
This approach to assessing CRA performance would tailor performance metrics to bank size and business strategy, as well as to local and cyclical conditions. The approach would tailor to banks' business models by establishing separate thresholds for substantially different lending products, such as mortgage loans and small business, small farm, and consumer loans, as well as separate retail lending and community development financing metrics.

The proposed metrics would also be tailored for different bank sizes. This is facilitated in part by allowing very small banks to retain the current evaluation procedures and in part by creating a separate community development test that would apply only to large banks. Tailoring is also an important consideration in data collection and reporting requirements. The proposed retail lending approach is designed so that it can be implemented in significant part with data that are readily available. In designing the community development approach, we have been mindful of burden as we consider any additional data that might be required to implement certain metrics.

Finally, as previously noted, the metrics are tailored for local conditions and cyclical considerations. The proposed threshold for each type of activity is calibrated to local conditions as they evolve over the cycle, and the community development finance metric uses an additional time-varying national rural or urban comparator.

The Path Ahead
Staff across the Federal Reserve System have devoted substantial time and effort to engaging with the other banking agencies in the CRA reform process. The analysis, data, and proposals I have discussed today have all been shared in greater detail with our counterparts at the other banking agencies in an effort to forge a common approach. We were hopeful our proposed approach could be incorporated into the proposed rulemaking that was released last month in order to seek public comment on a range of options.

Based on the best available data, we concluded that CRA metrics tailored to local conditions and the different sizes and business models of banks would best serve the credit needs of the communities that are at the heart of the statute. This tailored approach using targeted metrics also yielded more consistent and predictable overall ratings than any comprehensive uniform metric. Our analysis did not find a consistent relationship between CRA ratings and a uniform comprehensive ratio that adds together all of a bank's CRA-eligible activities in an area. Moreover, we want to be attentive to possible unintended consequences: Because a uniform comprehensive ratio would not reflect local conditions, which can vary greatly between communities and over the cycle, a bank could exert the same amount of effort in different areas or different points in the economic cycle with very different outcomes.

We continue to believe that a strong common set of interagency standards is the best outcome. By sharing our work publicly, we hope to solicit public input on a broader set of options for reform and find a way toward interagency agreement on the best approach. The process of sharing the data and analysis informing regulatory proposals and seeking public feedback on them is critical to the regulatory process. Given that reforms to the CRA regulations are likely to set expectations for a few decades, it is more important to get the reforms done right than to do them quickly. That requires giving external stakeholders sufficient time and analysis to provide meaningful feedback on a range of options for modernizing the regulations.

I will conclude by noting that the high level of engagement and commitment on the part of banks, community organizations, and other important stakeholders give me confidence that we will succeed in strengthening the CRA's core purpose of helping banks affirmatively meet the credit needs of their local LMI communities.
